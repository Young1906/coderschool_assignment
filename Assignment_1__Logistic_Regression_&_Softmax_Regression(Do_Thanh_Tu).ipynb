{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1__Logistic_Regression_&_Softmax_Regression(Do Thanh Tu).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "BODXyv9Hu8gm",
        "fobSVpxdzJCK",
        "PpjrfpjT0W85",
        "GpHPICzyL7eW",
        "ZmqEjanxNUt_",
        "Yy_5nMf7mOTW",
        "2Oz_NZPmmp4V",
        "SSvZIuG-oUwn",
        "gHzTgKgeqLMM"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Young1906/coderschool_assignment/blob/master/Assignment_1__Logistic_Regression_%26_Softmax_Regression(Do_Thanh_Tu).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "3LGpbq4tSiOw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bài tập về nhà 1\n",
        "# Logistic Regression & Softmax Regression"
      ]
    },
    {
      "metadata": {
        "id": "1e8vwb3zTACs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tóm tắt nội dung\n",
        "Trong bài tập này, các bạn sẽ sử dụng kiến thức đã học về logistic regression và softmax regression để giải quyết bài toán phân lớp."
      ]
    },
    {
      "metadata": {
        "id": "TbebJwTgTC9a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Giới thiệu"
      ]
    },
    {
      "metadata": {
        "id": "kESB1ROATIF7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Để có thể hoàn tất bài tập này, các bạn cần nắm rõ những kiến thức sau: \n",
        "- Logistic regression là gì, nguyên tắc hoạt động ra sao.\n",
        "- Softmax regression là gì và nguyên tắc hoạt động.\n",
        "- Cách lấy đạo hàm cho các tham số trong hai mô hình trên.\n",
        "- Giải thuật gradient descent.\n",
        "\n",
        "Bạn có thể tham khảo lại bài giảng của lớp để nắm vững các nội dung này. Ngoài ra, các bạn có thể đặt câu hỏi cho đội ngũ giảng dạy nếu có thắc mắc.\n",
        "\n",
        "Bài tập này sẽ gồm có hai bài chính:\n",
        "- Bài 1: phân loại hai lớp dùng **logistic regression**.\n",
        "- Bài 2: phân loại 10 lớp dùng **softmax regression**.\n",
        "\n",
        "Yêu cầu dành cho các bạn trong là giải quyết hai bài trên bằng **cả numpy và TensorFlow**.\n",
        "\n",
        "*Lưu ý: để tiện cho việc phân biệt giữa lớp python và lớp trong bài toán phân loại, người viết qui ước rằng khi viết **class** nghĩa là đang nói về python class, khi viết lớp nghĩa là đang ám chỉ **lớp** của dữ liệu cần phân loại*"
      ]
    },
    {
      "metadata": {
        "id": "eLgPOx1DpSwb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hướng dẫn làm và nộp bài\n",
        "Ở mỗi bài tập, các bạn sẽ được yêu cầu điền phần còn thiếu vào trong hàm, các cell để thực hiện phần bài làm sẽ có dòng đầu tiên như sau:\n",
        "```python\n",
        "# GRADED FUNCTION: <tên hàm>\n",
        "...\n",
        "```\n",
        "Trong cell đó, các bạn sẽ code phần đáp án của mình giữa 2 phần:\n",
        "```python\n",
        "### START CODE HERE ###\n",
        "<phần bài làm>\n",
        "### END CODE HERE ###\n",
        "```\n",
        "\n",
        "Sau khi thực hiện xong các bạn cần để chung file notebook và file `submit.py` vào cùng một thư mục trước khi nộp"
      ]
    },
    {
      "metadata": {
        "id": "pJ1iE641TaNY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tải dữ liệu và các hàm cần thiết"
      ]
    },
    {
      "metadata": {
        "id": "Gq7TH8EETxtM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Các bạn chạy cell bên dưới để tải bộ dữ liệu cũng như các hàm dùng để test cách cài đặt của các bạn:"
      ]
    },
    {
      "metadata": {
        "id": "QxnfQZEGTw2k",
        "colab_type": "code",
        "outputId": "27f4d3ff-8319-4125-b843-f676dc5718b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/vietai/assignment1-data.zip -O data.zip"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-28 19:52:05--  https://storage.googleapis.com/vietai/assignment1-data.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.128, 2404:6800:4003:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58185711 (55M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip             57%[==========>         ]  32.06M   160MB/s               \rdata.zip            100%[===================>]  55.49M   157MB/s    in 0.4s    \n",
            "\n",
            "2019-04-28 19:52:05 (157 MB/s) - ‘data.zip’ saved [58185711/58185711]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ETwlnPvIUQEo",
        "colab_type": "code",
        "outputId": "9cedb5f8-a2e5-4241-b200-b7ab0bc15d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip data.zip | awk 'BEGIN { ORS = \" \" } { print \".\" }'"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace data/vehicles.dat? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            ". . . . . . . . . . . . . . . . . . . "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "caPRYRLnVwu8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Các hàm bổ trợ dùng để đọc dữ liệu\n",
        "\n",
        "Nhóm TA sẽ giúp bạn định nghĩa các hàm bổ trợ trong việc đọc dữ liệu, các bạn không cần chỉnh sửa các hàm này:"
      ]
    },
    {
      "metadata": {
        "id": "1gHJ1OZONpud",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION\n",
        "import pickle\n",
        "import gzip\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import inspect\n",
        "from tensorflow.contrib.eager.python import tfe\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1JV27SB0l0fD",
        "colab_type": "code",
        "outputId": "f2e53a14-eb4a-4c1d-d006-9a207023fe8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['e', 'test']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "LGG6cXOPVPB2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "These functions helps you read data from data files\n",
        "Author: Kien Huynh\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def load_npy(file_name):\n",
        "    \"\"\"load_npy\n",
        "    Load numpy data file. This is needed as python 2.7 pickle uses ascii as default encoding method but python 3.x uses utf-8.abs\n",
        "\n",
        "    :param file_name: npy file path\n",
        "    \n",
        "    :return obj: loaded numpy object\n",
        "    \"\"\"\n",
        "    \n",
        "    if (sys.version_info[0] >= 3):\n",
        "        obj = np.load(file_name, encoding='latin1')\n",
        "    elif (sys.version_info[0] >=2):\n",
        "        obj = np.load(file_name)\n",
        "    \n",
        "    return obj\n",
        "\n",
        "\n",
        "def load_list(file_name):\n",
        "    \"\"\"load_list\n",
        "    Load a list object to file_name.\n",
        "\n",
        "    :param file_name: string, file name.\n",
        "    \"\"\"\n",
        "    end_of_file = False\n",
        "    list_obj = [] \n",
        "    f = open(file_name, 'rb')\n",
        "    python_version = sys.version_info[0]\n",
        "    while (not end_of_file):\n",
        "        try:\n",
        "            if (python_version >= 3):\n",
        "                list_obj.append(pickle.load(f, encoding='latin1'))\n",
        "            elif (python_version >=2):\n",
        "                list_obj.append(pickle.load(f))\n",
        "        except EOFError:\n",
        "            end_of_file = True\n",
        "            print(\"EOF Reached\")\n",
        "\n",
        "    f.close()\n",
        "    return list_obj \n",
        "\n",
        "\n",
        "def save_list(list_obj, file_name):\n",
        "    \"\"\"save_list\n",
        "    Save a list object to file_name\n",
        "    \n",
        "    :param list_obj: List of objects to be saved.\n",
        "    :param file_name: file name.\n",
        "    \"\"\"\n",
        "\n",
        "    f = open(file_name, 'wb')\n",
        "    for obj in list_obj:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "    f.close() \n",
        "\n",
        "\n",
        "def get_vehicle_data():\n",
        "    \"\"\"\n",
        "    Load vehicle data and return it as a list: [train_x, train_y, test_x, test_y]\n",
        "    \"\"\"\n",
        "    print('Reading vehicle data...')\n",
        "    train_x, train_y, test_x, test_y = load_list('./data/vehicles.dat')\n",
        "    train_x = np.transpose(train_x, (2,0,1))\n",
        "    test_x = np.transpose(test_x, (2,0,1)) \n",
        "\n",
        "    print('Done reading')\n",
        "    return train_x, train_y, test_x, test_y\n",
        "\n",
        "\n",
        "def read_mnist_gz(data_path, offset):\n",
        "    with gzip.open(data_path, 'rb') as f:\n",
        "        dataset = np.frombuffer(f.read(), dtype=np.uint8, offset=offset)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def get_mnist_data(sampling_step=20):\n",
        "    print('Reading fashion MNIST data...')\n",
        "    train_x = read_mnist_gz('./data/fashion-mnist/train-images-idx3-ubyte.gz', 16)\n",
        "    train_y = read_mnist_gz('./data/fashion-mnist/train-labels-idx1-ubyte.gz', 8)\n",
        "    test_x = read_mnist_gz('./data/fashion-mnist/t10k-images-idx3-ubyte.gz', 16)\n",
        "    test_y = read_mnist_gz('./data/fashion-mnist/t10k-labels-idx1-ubyte.gz', 8)\n",
        "    num_train = len(train_y)\n",
        "    num_test = len(test_y)\n",
        "\n",
        "    train_x = train_x.reshape((num_train, 28*28))\n",
        "    test_x = test_x.reshape((num_test, 28*28))\n",
        "\n",
        "    val_x = train_x[50000:,:]\n",
        "    val_y = train_y[50000:]\n",
        "    train_x = train_x[:50000,:]\n",
        "    train_y = train_y[:50000]\n",
        "\n",
        "    train_x = train_x[0::sampling_step,:]\n",
        "    train_y = train_y[0::sampling_step]\n",
        "    val_x = val_x[0::sampling_step,:]\n",
        "    val_y = val_y[0::sampling_step]\n",
        "    test_x = test_x[0::sampling_step,:]\n",
        "    test_y = test_y[0::sampling_step]\n",
        "    return train_x.astype(np.float32), train_y, val_x.astype(np.float32), val_y, test_x.astype(np.float32), test_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7yzZpItjWqe4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bài 1: Phân loại hai lớp dùng logistic regression"
      ]
    },
    {
      "metadata": {
        "id": "ecv42PtbW2YX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dữ liệu Vehicles"
      ]
    },
    {
      "metadata": {
        "id": "3cPITStuW6wW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tập dữ liệu Vehicles là tập gồm có 2 lớp, được gán nhãn lớp 0 và 1. Ta có thể đọc tập dữ liệu này bằng hàm `get_vehicle_data()`:"
      ]
    },
    {
      "metadata": {
        "id": "qwTC-jzcWiFS",
        "colab_type": "code",
        "outputId": "4d03da87-77dd-4617-9e27-e724f8d4dfff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "train_x, train_y, test_x, test_y = get_vehicle_data()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading vehicle data...\n",
            "EOF Reached\n",
            "Done reading\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oJOUX3RsXH6k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ở đây, `train_x` là một numpy tensor có kích thước `2400 × 64 × 64` (ý nghĩa: tập dữ liệu huấn luyện `train_x` có 2400 mẫu, mỗi mẫu là 1 ảnh có chiều cao (height) và rộng (width) bằng 64)"
      ]
    },
    {
      "metadata": {
        "id": "ygeWwMeLXCVG",
        "colab_type": "code",
        "outputId": "89d9afa0-d806-4d08-a155-e331f8f066a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_x.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2400, 64, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "sjePyisfXPES",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`train_y` là ma trận chứa nhãn ứng với mẫu dữ liệu trong `train_x`"
      ]
    },
    {
      "metadata": {
        "id": "rkUDMyxrXOCZ",
        "colab_type": "code",
        "outputId": "1f214319-ef62-45ea-9b59-62d12eb39c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_y.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2400, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "Ain-QssjXl_6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tương tự, `test_x` có kích thước `600 × 64 × 64`, mỗi hàng trong `test_y` biểu diễn cho nhãn của mỗi mẫu trong `test_x`"
      ]
    },
    {
      "metadata": {
        "id": "R_ceIkDBXWkp",
        "colab_type": "code",
        "outputId": "5d708b71-e657-47b4-caf9-5f69195cf794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(600, 64, 64)\n",
            "(600, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o_rh0p9xYF5S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hai tensor `train_x` và `train_y` được dùng cho việc huấn luyện mô hình phân loại; hai tensor `test_x` và `test_y` được dùng cho quá trình đánh giá (test)."
      ]
    },
    {
      "metadata": {
        "id": "03loyD0hYUrJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tập dữ liệu này gồm các ảnh xám (gray images), mỗi ảnh chứa một trong hai loại phương tiện di chuyển: xe máy và xe hơi. Mỗi ảnh có thể chứa trọn vẹn hoặc một phần phương tiện. Cần lưu ý là dữ liệu ảnh ở đây chưa được chuẩn hóa, nên các giá trị vẫn nằm trong khoảng từ 0 đến 255."
      ]
    },
    {
      "metadata": {
        "id": "GwY_Zi5VX7Hr",
        "colab_type": "code",
        "outputId": "002245d2-2365-4bff-87c9-ed74539c6061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "imgplot = plt.imshow(train_x[0])\n",
        "plt.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv/E9PJoQfuN7eDQh/Mb38GhC/G/isIAoHuKv4wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FzGjMBfurRIQ",
        "colab_type": "code",
        "outputId": "bdf206da-fb2e-4e57-9285-4c3a34fc3276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "imgplot = plt.imshow(train_x[2399])\n",
        "plt.show()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4Xt49CH+f7xM0cQ0kFbQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Rul5BLAlOMOC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Chuẩn hóa dữ liệu ảnh\n",
        "Như đã kể trên, ảnh đầu vào có giá trị từ 0 đến 255. Nếu ta đưa trực tiếp bộ ảnh vào quá trình huấn luyện sẽ làm cho gradient lớn. Vì vậy, trước khi huấn luyện, ta có thể sử dụng phương pháp chuẩn hóa dữ liệu để đưa trung bình (mean) của tập train về 0 và độ lệch chuẩn (standard deviation - std) của nó về 1.\n",
        "\n",
        "Đối với việc xử lý hình ảnh, ta có hai cách chuẩn hóa khác nhau:\n",
        "*   (a) Xem mỗi pixel trong ảnh là một đặc trưng riêng rẽ. Ví dụ, pixel [1, 3] và pixel [4, 2] là hai đặc trưng khác nhau, được tính mean và std riêng.\n",
        "*   (b) Xem các pixel khác nhau trong ảnh là cùng 1 loại đặc trưng. Lúc này, pixel [1, 3] và pixel [4, 2] được xem là cùng 1 loại đặc trưng, được tính mean và std chung.\n",
        "\n",
        "Trong mục này, bạn cần hiện thực cách chuẩn hóa (a) trong hàm ```normalize_per_pixel``` và cách (b) trong hàm ```normalize_all_pixel```. Giả sử ta có ```m``` ảnh train ```x_0..xm−1```, mỗi ảnh train có R hàng và C cột, thì mean và std tính theo cách (a) sẽ là:\n",
        "\n",
        "\\begin{equation}\n",
        "\\overline{x}_{rc}=\\frac{1}{m}\\sum_{i=0}^{m-1}x_{rc}^{(i)}, 0 \\le r \\le R-1,0 \\le c \\le C-1 \\tag{1}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\sigma_{rc}=\\sqrt{\\frac{1}{m}\\sum_{i=0}^{m-1}{(x_{rc}^{(i)}-\\overline{x}_{rc})^2}} \\tag{2}\n",
        "\\end{equation}\n",
        "\n",
        "Đối với cách (b) ta sẽ có:\n",
        "\n",
        "\\begin{equation}\n",
        "\\overline{x} = \\frac{1}{mRC}\\sum_{i=0}^{m-1}{\\sum_{r=0}^{R-1}{\\sum_{c=0}^{C-1}{x_{rc}^{(i)}}}} \\tag{3}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\sigma=\\sqrt{\\frac{1}{mRC}\\sum_{i=0}^{m-1}{\\sum_{r=0}^{R-1}{\\sum_{c=0}^{C-1}{(x_{rc}^{(i)}-\\overline{x})^2}}}} \\tag{4}\n",
        "\\end{equation}\n",
        "\n",
        "Sau khi có được mean và std trên toàn bộ data huấn luyện, ta chuẩn hóa các mẫu trong tập huấn luyện theo cách sau:\n",
        "\n",
        "\\begin{equation}\n",
        "x^{(i)} = \\frac{x^{(i)}-\\overline{x}}{\\sigma} \\tag{5}\n",
        "\\end{equation} \n",
        "\n",
        "Đối với cách (a), việc này sẽ được áp dụng riêng cho từng pixel trong số $R\\times{C}$. Với cách (b), thì ta dùng chung $\\overline{x}$ và $\\sigma$ trong công thức (3) và (4) cho toàn bộ tất cả các pixel.\n",
        "\n",
        "Cần lưu ý rằng $\\overline{x}$ và $\\sigma$ chỉ được tính trên $m$ mẫu dữ liệu huấn luyện. Sau đó, hai giá trị này sẽ được dùng lại để chuẩn hóa các mẫu dữ liệu test (và validation nếu có). Việc tính $\\overline{x}$ và $\\sigma$ mà có sử dụng các dữ liệu trong tập test là vi phạm nguyên tắc đánh giá các mô hình học máy. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bzRsJ5bWoGt9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 1: normalize_per_pixel "
      ]
    },
    {
      "metadata": {
        "id": "NB53DTTQmqCA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: normalize_per_pixel\n",
        "def normalize_per_pixel(train_x, test_x):\n",
        "    \"\"\"normalize_per_pixel\n",
        "    This function computes train mean and standard deviation on each pixel then applying data scaling on train_x and test_x using these computed values\n",
        "\n",
        "    :param train_x: train images, shape=(num_train, image_height, image_width)\n",
        "    :param test_x: test images, shape=(num_test, image_height, image_width)\n",
        "    \"\"\"\n",
        "    # train_mean and train_std should have the shape of (1, image_height, image_width)\n",
        "    ### START CODE HERE ### (≈4 lines)\n",
        "    train_mean = np.mean(train_x,axis=0,keepdims=True)\n",
        "    train_std = np.std(train_x,axis=0,keepdims=True)\n",
        "    train_x = (train_x - train_mean)/train_std\n",
        "    test_x = (test_x - train_mean)/train_std\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return train_x, test_x\n",
        "\n",
        "### SANITY CHECK\n",
        "train_x = np.arange(2*2*3).reshape(2,2,3)\n",
        "assert np.sum(normalize_per_pixel(train_x, train_x))==0, \"Wrong\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MSU-sZg3oM7N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 2: normalize_all_pixel"
      ]
    },
    {
      "metadata": {
        "id": "yguGEWe1msRo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: normalize_per_pixel\n",
        "def normalize_all_pixel(train_x, test_x):\n",
        "    \"\"\"normalize_all_pixel\n",
        "    This function computes train mean and standard deviation on all pixels then applying data scaling on train_x and test_x using these computed values\n",
        "\n",
        "    :param train_x: train images, shape=(num_train, image_height, image_width)\n",
        "    :param test_x: test images, shape=(num_test, image_height, image_width)\n",
        "    \"\"\"\n",
        "    # train_mean and train_std should have the shape of (1, 1, 1)\n",
        "    ### START CODE HERE ### (≈4 lines)\n",
        "    train_mean = np.mean(train_x)\n",
        "    train_std = np.std(train_x)\n",
        "    train_x = (train_x - train_mean)/train_std\n",
        "    test_x = (test_x - train_mean)/train_std\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return train_x, test_x\n",
        "\n",
        "### SANITY CHECK\n",
        "train_x = np.arange(2*2*3).reshape(2,2,3)\n",
        "assert np.sum(normalize_all_pixel(train_x, train_x))>0, \"Wrong\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c-nakFutobwo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Duỗi dữ liệu\n",
        "\n",
        "Dữ liệu ở bước trên vẫn còn ở dạng tensor 3D ($2400 \\times 64 \\times 64$). Để có thể thực hiện các phép nhân ma trận trong bài toán logistic regression, ta cần chuẩn chúng về dạng tensor 2D ($2400 \\times 4096$). Các bạn cần thực hiện bước này trong hàm `reshape2D`."
      ]
    },
    {
      "metadata": {
        "id": "fZP6cBp5osT5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 3: reshape2D"
      ]
    },
    {
      "metadata": {
        "id": "EWQ-uSJdtMzK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: reshape2D\n",
        "def reshape2D(tensor):\n",
        "    \"\"\"reshape_2D\n",
        "    Reshape our 3D tensors to 2D. A 3D tensor of shape (num_samples, image_height, image_width) must be reshaped into (num_samples, image_height*image_width)\n",
        "    \"\"\"\n",
        "    result = None\n",
        "    ### START CODE HERE ### (≈1 line)\n",
        "    result = tensor.reshape(tensor.shape[0],-1)\n",
        "    ### END CODE HERE ###\n",
        "    return result\n",
        "\n",
        "### SANITY CHECK\n",
        "tensor = np.arange(2*3*4).reshape(2,3,4)\n",
        "assert sum(reshape2D(tensor).shape)==14, \"Wrong\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LRCYuQCfpl1T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Thêm đặc trưng 1 vào dữ liệu\n",
        "Để tính tích vô hướng dễ dàng, nối thêm một cột có giá trị bằng 1 vào `train_x` và `test_x` (concatenate có axis=1). Trong file có sẵn hàm `add_one` và ta nên thực hiện code trong hàm này. Sau bước này, dữ liệu huấn luyện sẽ có kích thước $2400 \\times 4097$."
      ]
    },
    {
      "metadata": {
        "id": "GwSNZlg2qFCv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 4: add_one"
      ]
    },
    {
      "metadata": {
        "id": "0d732mHkqDWn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: add_one\n",
        "def add_one(x):\n",
        "    \"\"\"add_one\n",
        "    This function add ones as an additional feature for x\n",
        "\n",
        "    :param x: input data\n",
        "    \"\"\"\n",
        "    ### START CODE HERE ### (≈1 line)\n",
        "    x = np.concatenate([x, np.ones(x.shape[0]).reshape(x.shape[0],-1)],axis=1)\n",
        "    ### END CODE HERE ###\n",
        "    return x\n",
        "\n",
        "### SANITY CHECK\n",
        "x = np.arange(2*3).reshape(2,3)\n",
        "assert add_one(x).sum() == 17, \"Wrong\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5bgGyuw7rJWg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Class LogisticClassifier\n",
        "\n",
        "Nhằm hỗ trợ cho việc lập trình, đội ngũ TA cung cấp sẵn cho các bạn class **LogisticClassifier**. Một trong các thành phần chính của class LogisticClassifier là biết `w`, chứa tham số mà ta cần tìm khi huấn luyện. Tham số này là một mảng có số hàng bằng số đặc trưng của dữ liệu đầu vào, số cột bằng 1. Cụ thể trong bài toán phân loại ảnh xe này, `w` sẽ là một ma trận $4097\\times{1}$. `w` được khởi tạo ngẫu nhiên trong hàm `__init__(w_shape)`. Để truy xuất `w` từ bên trong class, ta dùng `self.w`, ví dụ:\n",
        "```python\n",
        "class logistic_classifier(object):\n",
        "    def feed_forward(self, x):\n",
        "        print(self.w)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "bvCZwnjktV88",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Để truy xuất w từ bên ngoài class, ta cần có một thực thể của class và gọi thông qua thực thể này, ví dụ:\n",
        "```python\n",
        "if __name__ == \"__main__\":\n",
        "    num_feature = train_x.shape[1]\n",
        "    bin_classifier = LogisticClassifier((num_feature, 1))\n",
        "    print(bin_classifier.w)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "EDSIBJPatljC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Đối với các hàm thuộc class **LogisticClassifier**, việc truy xuất cũng hoàn toàn giống với `w`. Chúng sẽ được mô tả chi tiết trong mục tiếp theo."
      ]
    },
    {
      "metadata": {
        "id": "-HvKyAwnteLa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION\n",
        "class LogisticClassifier(object):\n",
        "    def __init__(self, w_shape):\n",
        "        \"\"\"__init__\n",
        "        \n",
        "        :param w_shape: create w with shape w_shape using normal distribution\n",
        "        \"\"\"\n",
        "\n",
        "        mean = 0\n",
        "        std = 1\n",
        "        self.w = np.random.normal(0, np.sqrt(2./np.sum(w_shape)), w_shape)\n",
        "\n",
        "\n",
        "    def feed_forward(self, x):\n",
        "        \"\"\"TODO 5: feed_forward\n",
        "        This function compute the output of your logistic classification model\n",
        "        \n",
        "        :param x: input\n",
        "        \"\"\"\n",
        "        result = None\n",
        "        \n",
        "        ### START CODE HERE ### (≈2 lines)\n",
        "        z = np.dot(x,self.w)\n",
        "        y_hat = 1/(1+np.exp(-z))\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        return y_hat\n",
        "\n",
        "\n",
        "    def compute_loss(self, y, y_hat):\n",
        "        \"\"\"TODO 6: compute_loss\n",
        "        Compute the loss using y (label) and y_hat (predicted class)\n",
        "\n",
        "        :param y:  the label, the actual class of the samples\n",
        "        :param y_hat: the propabilitis that the given samples belong to class 1\n",
        "        \"\"\"\n",
        "        loss = 0\n",
        "        \n",
        "        ### START CODE HERE ### (≈2 lines)\n",
        "        loss = -np.mean(np.dot(np.transpose(y),np.log(y_hat))+np.dot(np.transpose(1-y),np.log(1-y_hat))) \n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        return loss\n",
        "\n",
        "\n",
        "    def get_grad(self, x, y, y_hat):\n",
        "        \"\"\"TODO 7: get_grad\n",
        "        Compute and return the gradient of w\n",
        "\n",
        "        :param x: input\n",
        "        :param y: the label, the actual class of the samples\n",
        "        :param y_hat: predicted y\n",
        "        \"\"\" \n",
        "        w_grad = None\n",
        "        \n",
        "        ### START CODE HERE ### (≈2 lines)\n",
        "        w_grad = np.dot(np.transpose(x),y_hat-y)/len(x)\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        return w_grad\n",
        "\n",
        "\n",
        "    def update_weight(self, grad, learning_rate):\n",
        "        \"\"\"TODO 8: update_weight\n",
        "        Update w using the computed gradient\n",
        "\n",
        "        :param grad: gradient computed from the loss\n",
        "        :param learning_rate: float, learning rate\n",
        "        \"\"\"\n",
        "        ### START CODE HERE ### (≈1 line)\n",
        "        self.w = self.w - learning_rate*grad\n",
        "        ### END CODE HERE ###\n",
        "        return self.w\n",
        "\n",
        "\n",
        "    def update_weight_momentum(self, grad, learning_rate, momentum, momentum_rate):\n",
        "        \"\"\"update_weight with momentum\n",
        "        BONUS:[YC1.8]\n",
        "        Update w using the algorithm with momnetum\n",
        "\n",
        "        :param grad: gradient computed from the loss\n",
        "        :param learning_rate: float, learning rate\n",
        "        :param momentum: the array storing momentum for training w, should have the same shape as w\n",
        "        :param momentum_rate: float, how much momentum to reuse after each loop (denoted as gamma in the document)\n",
        "        \"\"\"\n",
        "        ### START CODE HERE ### (≈3 lines)\n",
        "        momentum = momentum_rate*momentum + learning_rate*grad\n",
        "        self.w = self.w - momentum\n",
        "        ### END CODE HERE ###\n",
        "        return self.w\n",
        "\n",
        "\n",
        "    def numerical_check(self, x, y, grad):\n",
        "        eps = 0.000005\n",
        "        w_test0 = np.copy(self.w)\n",
        "        w_test1 = np.copy(self.w)\n",
        "        w_test0[2] = w_test0[2] - eps\n",
        "        w_test1[2] = w_test1[2] + eps\n",
        "\n",
        "        y_hat0 = np.dot(x, w_test0)\n",
        "        y_hat0 = 1. / (1. + np.exp(-y_hat0))\n",
        "        loss0 = self.compute_loss(y, y_hat0) \n",
        "\n",
        "        y_hat1 = np.dot(x, w_test1)\n",
        "        y_hat1 = 1. / (1. + np.exp(-y_hat1))\n",
        "        loss1 = self.compute_loss(y, y_hat1) \n",
        "\n",
        "        numerical_grad = (loss1 - loss0)/(2*eps)\n",
        "        print(numerical_grad)\n",
        "        print(grad[2])\n",
        "\n",
        "### SANITY CHECK        \n",
        "eps = 0.001        \n",
        "classifer = LogisticClassifier((3,1))\n",
        "classifer.w = np.arange(3*1).reshape(3,1)\n",
        "x = np.ones(2*3).reshape(2,3)\n",
        "y = 1\n",
        "y_hat = classifer.feed_forward(x)\n",
        "assert sum(y_hat)-1.905 < eps, \"Wrong\"\n",
        "loss = classifer.compute_loss(y, y_hat)\n",
        "assert loss - 0.048 < eps, \"Wrong\"\n",
        "grad = classifer.get_grad(x, y, y_hat)\n",
        "assert sum(grad) + 0.142 < eps, \"Wrong\"\n",
        "updateweight = classifer.update_weight(grad, 0.1)\n",
        "assert sum(updateweight) - 3.014 < eps, \"Wrong\"\n",
        "updatemomen = classifer.update_weight_momentum(grad, 0.1, 0.1, 0.1)\n",
        "assert sum(updatemomen) - 2.998 < eps, \"Wrong\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPll6bewuoqH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tính các giá trị phân loại\n",
        "\n",
        "Các giá trị phân loại, $\\hat{y}$, sẽ được tính trong hàm `feed_forward` của class `LogisticClassifier`. Công thức tính như sau:\n",
        "\n",
        "\\begin{equation}\n",
        "z = xw  \\tag{6}\n",
        "\\end{equation}\n",
        "\\begin{equation}\n",
        "\\hat{y} = \\frac{1}{1+e^{-z}} \\tag{7}\n",
        "\\end{equation}\n",
        "\n",
        "Ở đây, $w = [w_0, w_1,.., w_{4096}]^T$ là các tham số cần học (lưu trong biến `self.w` trong class `LogisticClassifier`). Lẽ ra công thức (6) được viết là $z=xw+w_{4096}$, tuy nhiên ở bước trên ta đã thêm 1 vào làm đặc trưng cuối cho tất cả các mẫu. Việc này giúp cho quá trình nhân ma trận và quản lý các biến gọn hơn."
      ]
    },
    {
      "metadata": {
        "id": "BODXyv9Hu8gm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 5: feed_forward\n",
        "\n",
        "Các bạn làm bài vào phần class [ở trên](https://colab.research.google.com/drive/1_DcdsXqPkAM3UB4GCHZHf_JlJRRRCA9T#scrollTo=-HvKyAwnteLa&line=21&uniqifier=1)"
      ]
    },
    {
      "metadata": {
        "id": "QhgYv_vEyNI2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tính độ lỗi\n",
        "\n",
        "Việc tính độ lỗi được thực hiện trong hàm `compute_loss` của class `LogisticClassifier`. Công thức tính độ lỗi như sau:\n",
        "\n",
        "\\begin{equation}\n",
        "J(w) = -\\frac{1}{m}\\sum_{i=0}^{m-1}(y^{(i)}\\log{\\hat{y}^{(i)}} + (1-y^{(i)})\\log(1-\\hat{y}^{(i)})) \\tag{8}\n",
        "\\end{equation}\n",
        "\n",
        "Trong đó:\n",
        "-  $y^{(i)}$ là nhãn của mẫu thứ $i$, mẫu thuộc lớp 0 sẽ có $y^{(i)}=0$, mẫu thuộc lớp 1 sẽ có $y^{(i)}=1$. Ta có thể truy cập các nhãn này thông qua biến `train_y` và `test_y`.\n",
        "- $\\hat{y}^{(i)} \\in (0, 1)$ là phần tử thứ $i$ trong vector $\\hat{y}$.\n",
        "- $m=2400$ là tổng số mẫu huấn luyện.\n",
        "\n",
        "\n",
        "Để tính trung bình trên ma trận theo hàng hoặc cột, ta có thể sử dụng hàm `np.mean()` với tham số axis tương ứng."
      ]
    },
    {
      "metadata": {
        "id": "fobSVpxdzJCK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 6: compute_loss\n",
        "\n",
        "Các bạn làm bài vào phần class [ở trên](https://colab.research.google.com/drive/1_DcdsXqPkAM3UB4GCHZHf_JlJRRRCA9T#scrollTo=-HvKyAwnteLa&line=21&uniqifier=1)"
      ]
    },
    {
      "metadata": {
        "id": "akV674wBzsi6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tính đạo hàm\n",
        "Để tính đạo hàm riêng cho thành phần $w_j$ trong $w$ trong hàm `get_grad`, ta dùng công thức sau:\n",
        "\\begin{equation}\n",
        "\\frac{\\partial  J(w_j)}{\\partial w_j} = \\frac{1}{m}\\sum_{i=1}^{m}(\\hat{y}^{(i)} - y^{(i)})x^{(i)}_j \\tag{9}\n",
        "\\end{equation}\n",
        "\n",
        "Trong trường hợp này, sau khi thêm 1 vào `train_x` thì ta sẽ có $0 \\le j \\le 4096$."
      ]
    },
    {
      "metadata": {
        "id": "PpjrfpjT0W85",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 7: get_grad\n",
        "Các bạn làm bài vào phần class [ở trên](https://colab.research.google.com/drive/1_DcdsXqPkAM3UB4GCHZHf_JlJRRRCA9T#scrollTo=-HvKyAwnteLa&line=21&uniqifier=1)"
      ]
    },
    {
      "metadata": {
        "id": "Sh9WycsLLocE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cập nhật $w$\n",
        "Để huấn luyện được mô hình phân loại trong hàm `update_weight`, ta cần cập nhật $w$ theo công thức sau:\n",
        "\\begin{equation}\n",
        "w = w - \\alpha\\times\\frac{\\partial  J(w)}{\\partial w} \\tag{10}\n",
        "\\end{equation}\n",
        "\n",
        "Với $\\alpha$ là hệ số học (`learning_rate`)."
      ]
    },
    {
      "metadata": {
        "id": "GpHPICzyL7eW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 8: update_weight\n",
        "Các bạn làm bài vào phần class [ở trên](https://colab.research.google.com/drive/1_DcdsXqPkAM3UB4GCHZHf_JlJRRRCA9T#scrollTo=-HvKyAwnteLa&line=21&uniqifier=1)"
      ]
    },
    {
      "metadata": {
        "id": "8KLXKJ_IM301",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cập nhật $w$ dùng momentum\n",
        "\n",
        "Giải thuật cập nhật trình bày trong phần trước có điểm yếu là chậm và dễ rơi vào tối ưu cục bộ. Tuy trong bài này, giải thuật đó cũng đủ để giải quyết, nhưng ta vẫn có thể sử dụng giải thuật có quán tính để việc huấn luyện diễn ra nhanh hơn.\n",
        "\n",
        "Khởi tạo ma trận quán tính trước khi vào vòng lặp chính:\n",
        "\\begin{equation}\n",
        "\\Delta w = 0 \\tag{11}\n",
        "\\end{equation}\n",
        "\n",
        "Ở đây, $\\Delta w$ là ma trận có kích thước bằng chính kích thước của $w$. Quá trình cập nhật $w$ sẽ được diễn ra như sau:\n",
        "\\begin{equation}\n",
        "\\Delta w = \\gamma\\Delta w + \\alpha\\frac{\\partial  J(w)}{\\partial w} \\tag{12}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "w = w - \\Delta w \\tag{13}\n",
        "\\end{equation}\n",
        "\n",
        "Với $\\gamma$ là hệ số quán tính (thường được đặt là 0.9)."
      ]
    },
    {
      "metadata": {
        "id": "ZmqEjanxNUt_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 9: update_weight_momentum\n",
        "\n",
        "Các bạn làm bài vào phần class [ở trên](https://colab.research.google.com/drive/1_DcdsXqPkAM3UB4GCHZHf_JlJRRRCA9T#scrollTo=-HvKyAwnteLa&line=21&uniqifier=1)"
      ]
    },
    {
      "metadata": {
        "id": "wrP0xiO8NvzD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Đánh giá mô hình phân loại\n",
        "Để đánh giá mô hình phân loại trên tập kiểm thử (`test_x` và `test_y`), trước tiên, ta cần thực hiện tính các giá trị phân loại trên`test_x`. Sau khi đã có các giá trị này, ta sử dụng các tiêu chí sau để đánh giá mô hình:\n",
        "\n",
        "\\begin{equation}\n",
        "Precision = \\frac{TP}{TP+FP} \\tag{14}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "Recall = \\frac{TP}{P} \\tag{15}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "F_1-score = 2\\times\\frac{Precision\\times Recall}{Precision+Recall} \\tag{16}\n",
        "\\end{equation}\n",
        "\n",
        "Trong đó:\n",
        "- Lớp positive là lớp có giá trị y = 1.\n",
        "- TP (true positive) là tổng số các mẫu mà mô hình dự đoán là positive ($\\hat{y}=1$) và thực sự có nhãn là positive ($y=1$)\n",
        "- FP (false positive) là tổng số các mẫu mô hình dự đoán là positive ($\\hat{y}=1$) nhưng thực chất có nhãn là negative ($y=0$)\n",
        "- P là tổng số mẫu positive trong tập test\n",
        "\\end{itemize}\n",
        "\n",
        "Nhiệm vụ của bạn trong bước này là tính các thông số trên trong hàm `test`. Khi tiến hành kiểm thử, người ra đề đã tính được các giá trị $Precision=0.766$, $Recall=0.830$ và $F_1-score=0.797$. Bạn hãy cố gắng hoàn thiện bài làm của mình để đạt kết quả tương tự hoặc tốt hơn."
      ]
    },
    {
      "metadata": {
        "id": "jz8g3el2Ork0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 10: test"
      ]
    },
    {
      "metadata": {
        "id": "8dYywqX6tOS9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION\n",
        "def test(y_hat, test_y):\n",
        "    \"\"\"test\n",
        "    Compute precision, recall and F1-score based on predicted test values\n",
        "\n",
        "    :param y_hat: predicted values, output of classifier.feed_forward\n",
        "    :param test_y: test labels\n",
        "    \"\"\"\n",
        "    \n",
        "    # [TODO 1.10]\n",
        "    # Compute test scores using test_y and y_hat\n",
        "\n",
        "    precision = 0\n",
        "    recall = 0\n",
        "    f1 = 0\n",
        "    ### START CODE HERE ### (≈7 lines)\n",
        "    y_hat = np.round(y_hat)\n",
        "    tp = np.sum(np.logical_and(y_hat == 1,test_y ==1 ))\n",
        "    fp = np.sum(np.logical_and(y_hat == 1,test_y ==0 ))\n",
        "    p = np.sum(test_y == 1)\n",
        "    precision = tp/(tp+fp)\n",
        "    recall = tp/p\n",
        "    f1 = 2*precision*recall/(precision+recall)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "### SANITY CHECK\n",
        "y_hat = np.arange(2).reshape(2, 1)/1.5\n",
        "test_y = np.arange(2).reshape(2, 1)\n",
        "assert sum(test(y_hat, test_y)) == 3, \"Wrong\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4e3JORB8PEfL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Vòng lặp huấn luyện\n",
        "\n",
        "Vòng lặp của quá trình huấn luyện được xây dựng trong đoạn code sau đây. Tất cả khung sườn cho việc thực thi đã được lập trình sẵn. Ta có thể thay đổi hai tham số tác động đến quá trình huấn luyện như sau:\n",
        "\n",
        "- `num_epoch`: số lượng vòng lặp cho quá trình huấn luyện.\n",
        "- `learning_rate`: hệ số học $\\alpha$.\n",
        "- `momentum_rate`: hệ số momentum $\\gamma$.\n",
        "- `epochs_to_draw`: số lượng epochs cần đạt được để vẽ đồ thị độ lỗi trong lúc huấn luyện."
      ]
    },
    {
      "metadata": {
        "id": "HEoEEijecqXi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_loss(all_loss):\n",
        "    plt.figure(1)\n",
        "    plt.clf()\n",
        "    plt.plot(all_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zkrzCU6lPak7",
        "colab_type": "code",
        "outputId": "cc0fbe18-1f4d-401b-f959-5a706d067cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Training { display-mode: \"both\" }\n",
        "normalize_method = \"per_pixel\" #@param [\"all_pixel\", \"per_pixel\"]\n",
        "update_weight_method = \"momentum\" #@param [\"normal\", \"momentum\"]\n",
        "num_epoch = 1000 #@param {type:\"integer\"}\n",
        "learning_rate = 0.01 #@param {type:\"number\"}\n",
        "momentum_rate = 0.9 #@param {type:\"number\"}\n",
        "epochs_to_draw = 500 #@param {type:\"integer\"}\n",
        "\n",
        "np.random.seed(2018)\n",
        "\n",
        "# Load data from file\n",
        "# Make sure that vehicles.dat is in data/\n",
        "train_x, train_y, test_x, test_y = get_vehicle_data()\n",
        "num_train = train_x.shape[0]\n",
        "num_test = test_x.shape[0]\n",
        "\n",
        "# Normalize our data: choose one of the two methods before training\n",
        "if normalize_method == \"all_pixel\":\n",
        "    train_x, test_x = normalize_all_pixel(train_x, test_x) \n",
        "else:\n",
        "    train_x, test_x = normalize_per_pixel(train_x, test_x) \n",
        "\n",
        "# Reshape our data\n",
        "# train_x: shape=(2400, 64, 64) -> shape=(2400, 64*64)\n",
        "# test_x: shape=(600, 64, 64) -> shape=(600, 64*64)\n",
        "train_x = reshape2D(train_x)\n",
        "test_x = reshape2D(test_x)\n",
        "\n",
        "# Pad 1 as the last feature of train_x and test_x\n",
        "train_x = add_one(train_x) \n",
        "test_x = add_one(test_x)\n",
        "\n",
        "# Create classifier\n",
        "num_feature = train_x.shape[1]\n",
        "bin_classifier = LogisticClassifier((num_feature, 1))\n",
        "momentum = np.zeros_like(bin_classifier.w)\n",
        "\n",
        "# Define hyper-parameters and train-related parameters\n",
        "all_loss = []\n",
        "plt.ion()\n",
        "for e in range(num_epoch):    \n",
        "    y_hat = bin_classifier.feed_forward(train_x)\n",
        "    loss = bin_classifier.compute_loss(train_y, y_hat)\n",
        "    grad = bin_classifier.get_grad(train_x, train_y, y_hat)\n",
        "\n",
        "    # Updating weight: choose either normal SGD or SGD with momentum\n",
        "    if update_weight_method == \"normal\":\n",
        "        bin_classifier.update_weight(grad, learning_rate)\n",
        "    else: \n",
        "        bin_classifier.update_weight_momentum(grad, learning_rate, momentum, momentum_rate)\n",
        "\n",
        "    all_loss.append(loss) \n",
        "\n",
        "    if (e % epochs_to_draw == epochs_to_draw-1):\n",
        "        plot_loss(all_loss)\n",
        "        plt.show()\n",
        "        plt.pause(0.1)     \n",
        "        print(\"Epoch %d: loss is %.5f\" % (e+1, loss))\n",
        "\n",
        "y_hat = bin_classifier.feed_forward(test_x)\n",
        "precision, recall, f1 = test(y_hat, test_y)\n",
        "print(\"Precision: %.3f\" % precision)\n",
        "print(\"Recall: %.3f\" % recall)\n",
        "print(\"F1-score: %.3f\" % f1)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading vehicle data...\n",
            "EOF Reached\n",
            "Done reading\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpKhFAAiIhlKASAikqH+P2mwcnLuIq0IAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 500: loss is 420.31548\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWrkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1000: loss is 317.26591\n",
            "Precision: 0.766\n",
            "Recall: 0.830\n",
            "F1-score: 0.797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2ZvVpS7iPvVr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Sau khi hoàn thành bài tập trên với numpy, các bạn tiến hành cài đặt lại với tensorflow. **"
      ]
    },
    {
      "metadata": {
        "id": "FZmlnIx6QlPu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Định Nghĩa Lớp LogisticRegressionTF"
      ]
    },
    {
      "metadata": {
        "id": "pVi-LxozARSO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Chúng ta sử dụng tensorflow eager execution để cài đặt mô hình logistic regression. Với tf eager execution, giá trị của các biến được tính toán ngay lập tức thay vì xây dựng computation graph để chạy sau đó. Một trong những lợi ích thiết thực nhất là giúp chúng ta dễ dàng debug mô hình, xây dựng được dynamic model.\n",
        "\n",
        "Để xây dựng mô hình bằng eager execution, chúng ta thường định nghĩa một lớp đối tượng như mình họa ở dưới\n",
        "\n",
        "Chúng ta nên kế thứa lớp Model và cài đặt 2 hàm chính\n",
        "-  init: khỏi tạo tất cả các tham số \n",
        "- call: hàm này sẽ feedforward cho chúng ta"
      ]
    },
    {
      "metadata": {
        "id": "s5BdlvtmE6Li",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LogisticRegressionTF(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, num_class):\n",
        "        super(LogisticRegressionTF, self).__init__()\n",
        "        # init all weights here\n",
        "        self.dense = tf.keras.layers.Dense(num_class)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        output = self.dense(inputs)\n",
        "        \n",
        "        # softmax op does not exist on the gpu\n",
        "        with tf.device('/cpu:0'):\n",
        "            output = tf.nn.softmax(output)        \n",
        "        return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O4s4l4aqreJX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 11: Định nghĩa one hot encoder"
      ]
    },
    {
      "metadata": {
        "id": "HQu3SvkzrdkK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: create_one_hot\n",
        "def create_one_hot(labels, num_k=10):\n",
        "    \"\"\"create_one_hot\n",
        "    This function creates a one-hot (one-of-k) matrix based on the given labels\n",
        "\n",
        "    :param labels: list of labels, each label is one of 0, 1, 2,... , num_k - 1\n",
        "    :param num_k: number of classes we want to classify\n",
        "    \"\"\"\n",
        "    eye_mat = None\n",
        "    ### START CODE HERE ### (≈2 lines)\n",
        "    eye_mat = np.zeros(shape=(len(labels),num_k))\n",
        "    eye_mat[np.arange(len(labels)),labels] = 1\n",
        "    ### END CODE HERE ###\n",
        "    return eye_mat\n",
        "\n",
        "### SANITY CHECK\n",
        "x = [1, 2, 3]\n",
        "y = create_one_hot(x, 4)\n",
        "assert y.shape == (3,4), \"Wrong\"\n",
        "assert sum(np.argmax(y, axis=0)) == 3, \"Wrong\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1qTPLe3RZERS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Huấn luyện mô hình với tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "D4bYf9IBZJHY",
        "colab_type": "code",
        "outputId": "00c118dd-1f16-413e-fe32-20ba2711436a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Training { display-mode: \"both\" }\n",
        "normalize_method = \"all_pixel\" #@param [\"all_pixel\", \"per_pixel\"]\n",
        "num_epoch = 10 #@param {type:\"integer\"}\n",
        "learning_rate = 0.001 #@param {type:\"number\"}\n",
        "batch_size = 32\n",
        "num_classes = 2\n",
        "np.random.seed(2018)\n",
        "tf.set_random_seed(2018)\n",
        "\n",
        "# Load data from file\n",
        "# Make sure that vehicles.dat is in data/\n",
        "train_x, train_y, test_x, test_y = get_vehicle_data()\n",
        "num_train = train_x.shape[0]\n",
        "num_test = test_x.shape[0]  \n",
        "\n",
        "#generate_unit_testcase(train_x.copy(), train_y.copy()) \n",
        "#logistic_unit_test()\n",
        "\n",
        "# Normalize our data: choose one of the two methods before training\n",
        "if normalize_method == \"all_pixel\":\n",
        "    train_x, test_x = normalize_all_pixel(train_x, test_x) \n",
        "else:\n",
        "    train_x, test_x = normalize_per_pixel(train_x, test_x) \n",
        "\n",
        "# Reshape our data\n",
        "# train_x: shape=(2400, 64, 64) -> shape=(2400, 64*64)\n",
        "# test_x: shape=(600, 64, 64) -> shape=(600, 64*64)\n",
        "train_x = reshape2D(train_x)\n",
        "test_x = reshape2D(test_x)\n",
        "train_y = create_one_hot(train_y.astype('int32').flatten().tolist(), num_k=2)\n",
        "test_y = create_one_hot(test_y.astype('int32').flatten().tolist(), num_k=2)\n",
        "\n",
        "device = '/cpu:0' if tfe.num_gpus() == 0 else '/gpu:0'\n",
        "\n",
        "with tf.device(device):\n",
        "    # build model and optimizer\n",
        "    model = LogisticRegressionTF(num_classes)\n",
        "    model.compile(optimizer=tf.train.AdamOptimizer(learning_rate), loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "\n",
        "    # train\n",
        "    model.fit(train_x, train_y, batch_size=batch_size, epochs=num_epoch,\n",
        "              validation_data=(test_x, test_y), verbose=2)\n",
        "\n",
        "    # evaluate on test set\n",
        "    scores = model.evaluate(test_x, test_y, 32, verbose=2)\n",
        "    \n",
        "    y_hat = model.predict(test_x)\n",
        "    precision, recall, f1 = test(y_hat, test_y)\n",
        "    print(\"Precision: %.3f\" % precision)\n",
        "    print(\"Recall: %.3f\" % recall)\n",
        "    print(\"F1-score: %.3f\" % f1)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading vehicle data...\n",
            "EOF Reached\n",
            "Done reading\n",
            "Train on 2400 samples, validate on 600 samples\n",
            "Epoch 1/10\n",
            " - 1s - loss: 0.5118 - acc: 0.8083 - val_loss: 0.5372 - val_acc: 0.7667\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.3263 - acc: 0.8704 - val_loss: 0.5589 - val_acc: 0.7617\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.2680 - acc: 0.8896 - val_loss: 0.6135 - val_acc: 0.7717\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.2571 - acc: 0.8946 - val_loss: 0.5826 - val_acc: 0.7683\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.2282 - acc: 0.9079 - val_loss: 0.6472 - val_acc: 0.7467\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.2039 - acc: 0.9167 - val_loss: 0.6398 - val_acc: 0.7533\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.1685 - acc: 0.9346 - val_loss: 0.6482 - val_acc: 0.7617\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.1547 - acc: 0.9429 - val_loss: 0.6945 - val_acc: 0.7450\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.1502 - acc: 0.9429 - val_loss: 0.7095 - val_acc: 0.7650\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.1282 - acc: 0.9538 - val_loss: 0.7098 - val_acc: 0.7583\n",
            " - 0s - loss: 0.7098 - acc: 0.7583\n",
            "Precision: 0.758\n",
            "Recall: 0.758\n",
            "F1-score: 0.758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9U9Se7dsfv9P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bài 2: Phân loại mười lớp"
      ]
    },
    {
      "metadata": {
        "id": "cLYyjVEzf-6A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dữ liệu fashion MNIST\n",
        "\n",
        "Ta có thể đọc tập dữ liệu này bằng hàm `get_mnist_data()`:"
      ]
    },
    {
      "metadata": {
        "id": "jOMEH7P8enH1",
        "colab_type": "code",
        "outputId": "7d585a44-e981-4b7a-ce94-f9b8a045f121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_x, train_y, val_x, val_y, test_x, test_y = get_mnist_data()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading fashion MNIST data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "23aegpJ3gOVJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tập dữ liệu này gồm các ảnh xám kích thước $28 \\times 28$. Có tất cả 50000 ảnh train, 10000 ảnh validation và 10000 ảnh test. Mỗi ảnh thuộc một trong 10 loại quần, áo, giày, túi xách, v.v. Tuy nhiên trong bài tập này ta chỉ lấy 2500 ảnh train, 500 ảnh valication và 500 ảnh test\n"
      ]
    },
    {
      "metadata": {
        "id": "F1pvh-JTgK2q",
        "colab_type": "code",
        "outputId": "534bf9e8-2db1-41f9-84f0-79ab170b10a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(val_x.shape)\n",
        "print(val_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2500, 784)\n",
            "(2500,)\n",
            "(500, 784)\n",
            "(500,)\n",
            "(500, 784)\n",
            "(500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mE7g9Yt4gxDB",
        "colab_type": "code",
        "outputId": "041aba0f-ab31-484b-e76e-ec1ead9c46a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "imgplot = plt.imshow(train_x[0].reshape(28,28))\n",
        "plt.show()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lKyk9vYKhLik",
        "colab_type": "code",
        "outputId": "61397b17-0493-4630-d729-1e40a16e6b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "imgplot = plt.imshow(train_x[100].reshape(28,28))\n",
        "plt.show()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE3FJREFUeJzt3X9sndV5B/Dvc6+v7dgxJM4PJ3FM\nE0IGS7M2bCYwFW1tWSllTAFNCkQIBYkRtBUJNKSNMVVDmiahrtDxx9TJQNTQMdpJhZJtEW2arUOl\nwGKyLAkECEmd4sSJHZLUv32v7332h98gA36fY+6v95rn+5Ei2/e5597jN/76vb7nPeeIqoKI/Ekl\n3QEiSgbDT+QUw0/kFMNP5BTDT+QUw0/kFMNP5BTDT+QUw0/kVF01n6xeGrQRzdV8SgrQlia7Xidm\nPT02abcfn/jEfaLijWMEWZ2w/9MiJYVfRG4A8DiANIAnVfUR6/6NaMbVcl0pT0lllrvmd8z6+KKM\nWV9w4H2znj985BP3iYr3mu6Z9X2LftkvImkA/wjgawDWAdgiIuuKfTwiqq5S/ubfCOBdVT2mqlkA\n3wewqTzdIqJKKyX87QDem/Z1b3Tbh4jINhHpFpHuHPj3H1GtqPi7/arapaqdqtqZQUOln46IZqmU\n8J8A0DHt65XRbUQ0B5QS/r0A1orIahGpB3AbgJ3l6RYRVVrRQ32qOiki9wL4MaaG+rar6htl6xl9\n4P0/+V2z/ld/8UxsbVztobqOzH6zXo+8Wc8ibdaPZZfG1v7z3BVm24G7V5j1wqG3zLpJAkPhDla4\nKmmcX1V3AdhVpr4QURXx8l4ipxh+IqcYfiKnGH4ipxh+IqcYfiKnqjqfn2b2zpOdZn3fVx8163sn\nLo6tDWRbzLZHCsvMekbs+fohGYm/TuC+ZT812+b/zR6Lv/PJ+8x6x9/9Ir4YGsd3cB0Az/xETjH8\nRE4x/EROMfxETjH8RE4x/EROcahvlqQu/lDppD0cNrz5GrP+i+u/ZdZ/PNph1pfUDcbWcmr/Fzel\n7KXVfjkRPyUXAJrSdvvW9Ehs7Whuidl2tGCv/PTiPd8067e/+UBsren518y2UmdPhdZc1qzPBTzz\nEznF8BM5xfATOcXwEznF8BM5xfATOcXwEznFcf5ZCo3lW858zp4eemRyvllvTOXMehrx00vbMufN\ntkP5eWb9N+fZ+7DUG1N2AeBULn668dnA991aN2zWfza6yqyHxvItn4Zx/BCe+YmcYviJnGL4iZxi\n+ImcYviJnGL4iZxi+ImcKmmcX0R6AAwByAOYVFV7DeokVXAp5pWv2uPVjy17zKy/PLbGrC8w5sQD\nQE9ucWwtNI6fU3uL7dPGOD0AZFL29Q/WfP5FgXH89wPXAbSkx8z6uf9YG1tb+IdHzLYelOMiny+p\n6pkyPA4RVRFf9hM5VWr4FcBPROR1EdlWjg4RUXWU+rL/WlU9ISJLAewWkbdU9aXpd4h+KWwDgEY0\nlfh0RFQuJZ35VfVE9LEfwPMANs5wny5V7VTVzgzsBRmJqHqKDr+INItIy4XPAVwP4FC5OkZElVXK\ny/42AM/L1BBaHYB/UdUXy9IrIqq4osOvqscAfL6MfaksCbzIUXte+sgfXx1bu2PJE2bbXcPrzbo1\nFg6Ex+qHCo2xNWuLbAC4tP59sz5esNevHywU37fxnP3YzYE9BU7mFpr1rnX/HFu79W/vN9uu+sYr\nZh0p+/oIFOzjXgs41EfkFMNP5BTDT+QUw0/kFMNP5BTDT+SUn6W7Sxx6GbvzXGxtXO0hq9BwWz7w\nOzg0pdea2hraonswHz8UN5v2IU2p+CWwG8VeHju0LHhLatysv5VdFlu78stvm23PfcMsz4mhvBCe\n+YmcYviJnGL4iZxi+ImcYviJnGL4iZxi+Imc8jPOX6I//409sbWRgr1CUWvaXqI6NJYe2so6JcUv\nOx5SUHvJ89D24dY1DqHjVoC9LPhooL11/URz2r7GIP6qjk8PnvmJnGL4iZxi+ImcYviJnGL4iZxi\n+ImcYviJnOI4/ywdn4jfBvvyxj6z7dK6IbP+q9yiovp0gbXNdhoFs21orDy0FkEmsOS5dY1CQ+Aa\ngXOTzWa9LfNrs34yG7+092+19JptT638rFmf7D1h1ucCnvmJnGL4iZxi+ImcYviJnGL4iZxi+Imc\nYviJnAqO84vIdgA3AehX1fXRba0AfgBgFYAeAJtVdU5PgU5ffplZv6xxd2zN2oYaADoy9jbY5/NN\nZj20FbUlJaFx/nqzbq27D4T3LMgjfj2A0HNb1y8AwBX19vUVvdnW2NqKjP3jOtTZbtbnORnn/y6A\nGz5y24MA9qjqWgB7oq+JaA4Jhl9VXwJw9iM3bwKwI/p8B4Cby9wvIqqwYv/mb1PVC6+5TgFoK1N/\niKhKSn7DT1UVQOwiciKyTUS6RaQ7h4lSn46IyqTY8J8WkeUAEH3sj7ujqnapaqeqdmZgTyIhouop\nNvw7AWyNPt8K4IXydIeIqiUYfhF5FsArAC4XkV4RuQvAIwC+IiJHAPxB9DURzSHBcX5V3RJTuq7M\nfUnU2c74+foAsCA1Glsbys8z29YH5tSHxuJD493mYxvj7EB4vn5rnb3nQGhPActo3v4zsCU9btYb\nxV7X31If+L5P/L59XrzsR0U/dc3gFX5ETjH8RE4x/EROMfxETjH8RE4x/EROcenuyEBn8W1D21Q3\nBIaVxgv2tNj5gSEva2psS8pu25dbYNbfGLWntq5pjL24E4C9NHjouIW0pu32i40l07OB4dP5q+1l\nwT8NeOYncorhJ3KK4SdyiuEncorhJ3KK4SdyiuEncorj/JHmwLjuqBa/ClFjYMpuaHppQe3f0en4\nVdSCQtcQLKwbMeuhZctLmXYbmurcJPZ0ZWtKcE7tH/2bVx8w66/CvjZjLuCZn8gphp/IKYafyCmG\nn8gphp/IKYafyCmGn8gpjvNHrlr2nlm35n+HltZuTtnj0UvqBs36qcmLzboltDR3qF7qNQbWFt2h\n57baAkCTBLYHV2t7cPu6jVsu2mfWX8XVZn0u4JmfyCmGn8gphp/IKYafyCmGn8gphp/IKYafyKng\nOL+IbAdwE4B+VV0f3fYwgLsBDER3e0hVd1Wqk9Xw5YWHzbq1tn42MDd8pGCPhYfGu5tSWbM+nI+f\nU58JzKefCOwZEJpTH7oOIG88fmgL7tD3/e+jS8x6s9F+qGBvq35Zpvg1EuaK2Zz5vwvghhlu/7aq\nboj+zengE3kUDL+qvgTgbBX6QkRVVMrf/PeKyAER2S4iC8vWIyKqimLD/x0AawBsANAH4NG4O4rI\nNhHpFpHuHCaKfDoiKreiwq+qp1U1r6oFAE8A2Gjct0tVO1W1M4PiF8EkovIqKvwisnzal7cAOFSe\n7hBRtcxmqO9ZAF8EsFhEegH8DYAvisgGAAqgB8A9FewjEVVAMPyqumWGm5+qQF8StaGh16y/PLYm\nttYo9nh0yMmc/X5pc8p+r8RaT6AxZe9hHxpLbwi0D10nMG5cAxGar39Fw0mzvu17f2bW/+H2+B/T\nRrG/r5C6S1eZ9cljPSU9fjXwCj8ipxh+IqcYfiKnGH4ipxh+IqcYfiKnuHR3ZEXansJpTZvd2PxL\ns+2fHr3VrN+2Yq9Zb00Pm/WByZbYmjUVGQhP2Q0tSx5qb63sfSYX328AaJ9vf98Q+/+se3R1bG11\nw0BsDQCGCvZU6NG1i816PYf6iKhWMfxETjH8RE4x/EROMfxETjH8RE4x/EROuRnnlwZ7FaGmlD0e\nbk1t/dWkPSX3yMmlZn3d6hNmvSdnjylb01NDW1G3pMbMekjo8a1lyUPTid+bvMis13/uvFk/NRG/\ntXlonD804Xdkmf3zUh9oXwt45idyiuEncorhJ3KK4SdyiuEncorhJ3KK4Sdyys04f+qSdrOeU3ub\nbGss/b8HrzDbXt5+OvDc9pz5gcB4t7W0d2iJ6kNjK816aOnvpZlBu70xYj4a2MFp//glZv22S/eZ\n9da6+PUAQusc5AI7dOda7GXH5wKe+YmcYviJnGL4iZxi+ImcYviJnGL4iZxi+ImcCo7zi0gHgKcB\ntGFqFfYuVX1cRFoB/ADAKgA9ADar6rnKdbU0uRXxc7sBIBX4PZiR+HXc+8btx76q9bhZH1d7zLk9\nYx/WfuM6AGs+PQCsn2dvTT5YmGfWC2qPd+eN43px3ajZNrT9dyZlr62/pG4otnYsu8Rse75gz8if\ntA/LnDCbM/8kgAdUdR2AawB8XUTWAXgQwB5VXQtgT/Q1Ec0RwfCrap+q7os+HwJwGEA7gE0AdkR3\n2wHg5kp1kojK7xP9zS8iqwBcCeA1AG2q2heVTmHqzwIimiNmHX4RmQ/ghwDuV9UPXdCtqoqYXdlE\nZJuIdItIdw7x16ATUXXNKvwiksFU8J9R1eeim0+LyPKovhxA/0xtVbVLVTtVtTMTmMhBRNUTDL+I\nCICnABxW1cemlXYC2Bp9vhXAC+XvHhFVymym9H4BwB0ADorI/ui2hwA8AuBfReQuAMcBbK5MF8tj\ntM1+1dEg9qEYMoa8bm97xWybgT3cdjRrv11yUWB57UaJXwI7NHXVGsIEgPpAPRv6EdLAFt6GPOxh\nxLS1/zeARcbW5sdgD/WNqD3Ul704MOd3DgiGX1V/DsT+L1xX3u4QUbXwCj8ipxh+IqcYfiKnGH4i\npxh+IqcYfiKn3CzdPdxu/54bU3u76P5c/LTZP5p/2Gy7d3yFWQ9Ni02JPVZeMKYEh5YFD43zh6YE\nZ9X+EbLah/tmP/doPrQ9ePz31pE5a7Y9n28y67kFxV+/UCt45idyiuEncorhJ3KK4SdyiuEncorh\nJ3KK4Sdyys04f2ip5dHAFt3WmPNIwf4dGpqXnhJ7bnhB7cdPIX7MObTFdjrw3CGhsfqC8b3nAtcI\nhL7vEOvxm4xtzQGgEDgvapP98zIX8MxP5BTDT+QUw0/kFMNP5BTDT+QUw0/kFMNP5JSbcf7Rlfa8\n9Z+N2XPul2YGY2tDgS22SzVSsOetp435/tY1AACwID1i1kNj8aF9Acy+qX2NQSqw5n/4+on49la/\nACAdOG6fBjzzEznF8BM5xfATOcXwEznF8BM5xfATOcXwEzkVHOcXkQ4ATwNoA6AAulT1cRF5GMDd\nAAaiuz6kqrsq1dFSdawZMOuh8ezhfGNsLbTGe31g/fnQnPgzky1mvSltz00vRajv46FrHIyhfOuY\nAuHjkrIeHMDZ/HyzbunJLrbvMDH3z5uzuchnEsADqrpPRFoAvC4iu6Pat1X1W5XrHhFVSjD8qtoH\noC/6fEhEDgNor3THiKiyPtFrFxFZBeBKAK9FN90rIgdEZLuILIxps01EukWkO4fKvTwlok9m1uEX\nkfkAfgjgflUdBPAdAGsAbMDUK4NHZ2qnql2q2qmqnRnY16gTUfXMKvwiksFU8J9R1ecAQFVPq2pe\nVQsAngCwsXLdJKJyC4ZfRATAUwAOq+pj025fPu1utwA4VP7uEVGlzObd/i8AuAPAQRHZH932EIAt\nIrIBU4M5PQDuqUgPy2TDol6z3ij2Etc3tRyMrf39qevNtk90vGzWgeFAvXh9k/ZjHw+sad6WHjPr\nC1L2+SMj8fWM2EN5IQ1iDzPmjSnBu8fs7/v+hT1m/dhV/2vW3zartWE27/b/HJhx4nTNjukTUdjc\nv1KBiIrC8BM5xfATOcXwEznF8BM5xfATOeVm6e63O+1x/KOrv2TWC/1n4msj9vLXN372VrN+7vMz\nTov4wPBK+3d0bn781NbsKns+xfKl5+3nHrcvyR4802zWZST+R6z+14Glt7N2vfWwPd24+bn/ia29\n80+dZlsJTNm95EV7ae8G7DXrtYBnfiKnGH4ipxh+IqcYfiKnGH4ipxh+IqcYfiKnRAPbJJf1yUQG\nAByfdtNiAPED6Mmq1b7Var8A9q1Y5ezbZ1R1yWzuWNXwf+zJRbpV1b7aIiG12rda7RfAvhUrqb7x\nZT+RUww/kVNJh78r4ee31GrfarVfAPtWrET6lujf/ESUnKTP/ESUkETCLyI3iMjbIvKuiDyYRB/i\niEiPiBwUkf0i0p1wX7aLSL+IHJp2W6uI7BaRI9FHez5wdfv2sIiciI7dfhG5MaG+dYjIf4nImyLy\nhojcF92e6LEz+pXIcav6y34RSQN4B8BXAPQC2Atgi6q+WdWOxBCRHgCdqpr4mLCI/B6mFvV/WlXX\nR7d9E8BZVX0k+sW5UFX/skb69jCA4aR3bo42lFk+fWdpADcDuBMJHjujX5uRwHFL4sy/EcC7qnpM\nVbMAvg9gUwL9qHmq+hKAsx+5eROAHdHnOzD1w1N1MX2rCarap6r7os+HAFzYWTrRY2f0KxFJhL8d\nwHvTvu5FbW35rQB+IiKvi8i2pDszg7Zo23QAOAWgLcnOzCC4c3M1fWRn6Zo5dsXseF1ufMPv465V\n1d8G8DUAX49e3tYknfqbrZaGa2a1c3O1zLCz9AeSPHbF7nhdbkmE/wSAjmlfr4xuqwmqeiL62A/g\nedTe7sOnL2ySGn3sT7g/H6ilnZtn2lkaNXDsamnH6yTCvxfAWhFZLSL1AG4DsDOBfnyMiDRHb8RA\nRJoBXI/a2314J4Ct0edbAbyQYF8+pFZ2bo7bWRoJH7ua2/FaVav+D8CNmHrH/yiAv06iDzH9uhTA\n/0X/3ki6bwCexdTLwBym3hu5C8AiAHsAHAHwUwCtNdS37wE4COAApoK2PKG+XYupl/QHAOyP/t2Y\n9LEz+pXIceMVfkRO8Q0/IqcYfiKnGH4ipxh+IqcYfiKnGH4ipxh+IqcYfiKn/h80syGRGYrVMgAA\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "eRUHcjC2hkEv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lưu ý là giá trị của `train_y` và `test_y` sẽ có thể là 0, 1,.., 9 thay vì 0 và 1 như bài 1. Ngoài ra, dữ liệu này khi được đọc lên đã có dạng tensor 2D ($3500 \\times 784$)."
      ]
    },
    {
      "metadata": {
        "id": "1_9FgB3Jh8iV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Class SoftmaxClassifier\n",
        "\n",
        "Class này thừa kế lại một số thuộc tính từ class LogisticClassifier như `__init__`, `w`. Riêng với các hàm `feed_forward`, `compute_loss` và `get_grad` ta cần phải hiện thực lại."
      ]
    },
    {
      "metadata": {
        "id": "jKsh9eo5hOMq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION\n",
        "class SoftmaxClassifier(LogisticClassifier):\n",
        "    def __init__(self, w_shape):\n",
        "        \"\"\"__init__\n",
        "        \n",
        "        :param w_shape: create w with shape w_shape using normal distribution\n",
        "        \"\"\"\n",
        "        super(SoftmaxClassifier, self).__init__(w_shape)\n",
        "\n",
        "\n",
        "    def softmax(self, x):\n",
        "        \"\"\"TODO 20: softmax\n",
        "\n",
        "        :param x: input\n",
        "        \"\"\"\n",
        "        result = None\n",
        "        ### START CODE HERE ### (≈4 lines)\n",
        "        z_max = np.max(x, axis = 1, keepdims = 1)\n",
        "        z_apo = np.exp(x - z_max)\n",
        "        s = np.sum(z_apo, axis=1, keepdims = 1)\n",
        "        result = z_apo/s\n",
        "        ### END CODE HERE ###\n",
        "        return result\n",
        "\n",
        "\n",
        "    def feed_forward(self, x):\n",
        "        \"\"\"TODO 19: feed_forward\n",
        "        This function compute the output of your softmax regression model\n",
        "        \n",
        "        :param x: input\n",
        "        \"\"\"\n",
        "        result = None\n",
        "        ### START CODE HERE ### (≈2 lines)\n",
        "        z = np.dot(x, self.w)\n",
        "        result = self.softmax(z)\n",
        "        ### END CODE HERE ###\n",
        "        return result\n",
        "\n",
        "\n",
        "    def compute_loss(self, y, y_hat):\n",
        "        \"\"\"TODO 21: compute_loss\n",
        "        Compute the loss using y (label) and y_hat (predicted class)\n",
        "\n",
        "        :param y:  the label, the actual class of the samples\n",
        "        :param y_hat: the class probabilities of all samples in our data\n",
        "        \"\"\"\n",
        "        loss = 0\n",
        "        ### START CODE HERE ### (≈3 lines)\n",
        "        loss = -np.mean(np.dot(np.transpose(y),np.log(y_hat)))\n",
        "        ### END CODE HERE ###\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def get_grad(self, x, y, y_hat):\n",
        "        \"\"\"TODO 22: get_grad\n",
        "        Compute and return the gradient of w\n",
        "\n",
        "        :param loss: computed loss between y_hat and y in the train dataset\n",
        "        :param y_hat: predicted y\n",
        "        \"\"\" \n",
        "        w_grad = None\n",
        "        ### START CODE HERE ### (≈2 lines)\n",
        "        m = len(x)\n",
        "        w_grad = 1/m*np.dot(np.transpose(x),y_hat-y)\n",
        "        ### END CODE HERE ###\n",
        "        return w_grad\n",
        "   \n",
        "\n",
        "    def numerical_check(self, x, y, grad):\n",
        "        i = 3\n",
        "        j = 0\n",
        "        eps = 0.000005\n",
        "        w_test0 = np.copy(self.w)\n",
        "        w_test1 = np.copy(self.w)\n",
        "        w_test0[i,j] = w_test0[i,j] - eps\n",
        "        w_test1[i,j] = w_test1[i,j] + eps\n",
        "\n",
        "        y_hat0 = np.dot(x, w_test0)\n",
        "        y_hat0 = self.softmax(y_hat0)\n",
        "        loss0 = self.compute_loss(y, y_hat0) \n",
        "\n",
        "        y_hat1 = np.dot(x, w_test1)\n",
        "        y_hat1 = self.softmax(y_hat1)\n",
        "        loss1 = self.compute_loss(y, y_hat1) \n",
        "\n",
        "        numerical_grad = (loss1 - loss0)/(2*eps)\n",
        "        print(numerical_grad)\n",
        "        print(grad[i,j])\n",
        "        \n",
        "### SANITY CHECK\n",
        "eps = 0.001        \n",
        "classifer = SoftmaxClassifier((3,1))\n",
        "classifer.w = np.arange(3*1).reshape(3,1)\n",
        "x = np.ones(2*3).reshape(2,3)/2\n",
        "y = 0\n",
        "y_hat = classifer.feed_forward(x)\n",
        "assert sum(y_hat)==2, \"Wrong\"\n",
        "loss = classifer.compute_loss(y, y_hat)\n",
        "assert loss==0, \"Wrong\"\n",
        "grad = classifer.get_grad(x, y, y_hat)\n",
        "assert sum(grad)==1.5, \"Wrong\"\n",
        "updateweight = classifer.update_weight(grad, 0.1)\n",
        "assert sum(updateweight) - 2.849 < eps, \"Wrong\"\n",
        "updatemomen = classifer.update_weight_momentum(grad, 0.1, 0.1, 0.1)\n",
        "assert sum(updatemomen) - 2.67 < eps, \"Wrong\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9fRHnz3FizC0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Chuẩn hóa dữ liệu\n",
        "Trong bước này, ta sẽ chuẩn hóa dữ liệu `train_x`, `val_x` và `test_x` theo cách (b) đã đề cập trong phần trước. Tuy nhiên, do tập dữ liệu MNIST khi load đã được đặt dưới dạng tensor 2D, nên trong công thức tính tổng chỉ còn $m$ và $R=784$."
      ]
    },
    {
      "metadata": {
        "id": "IGDUBrGmjand",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 12: normalize"
      ]
    },
    {
      "metadata": {
        "id": "BfgkYMdLivKW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: normalize\n",
        "def normalize(train_x, val_x, test_x):\n",
        "    \"\"\"normalize\n",
        "    This function computes train mean and standard deviation on all pixels then applying data scaling on train_x, val_x and test_x using these computed values\n",
        "    Note that in this classification problem, the data is already flatten into a shape of (num_samples, image_width*image_height)\n",
        "\n",
        "    :param train_x: train images, shape=(num_train, image_height*image_width)\n",
        "    :param val_x: validation images, shape=(num_val, image_height*image_width)\n",
        "    :param test_x: test images, shape=(num_test, image_height*image_width)\n",
        "    \"\"\"\n",
        "    # train_mean and train_std should have the shape of (1, 1)\n",
        "    ### START CODE HERE ### (≈5 lines)\n",
        "    train_mean = np.mean(train_x)\n",
        "    train_std = np.std(train_x)\n",
        "    train_x = (train_x - train_mean)/train_std\n",
        "    val_x = (val_x - train_mean)/train_std\n",
        "    test_x = (test_x - train_mean)/train_std\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return train_x, val_x, test_x\n",
        "\n",
        "### SANITY CHECK\n",
        "train_x = np.arange(2*4).reshape(2, 4)\n",
        "x, y, z = normalize(train_x, train_x, train_x)\n",
        "assert np.sum((x, y, z)) == 0, \"Wrong\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RlidH1M6jjOe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tiền xử lý vector label thành dạng one-hot\n",
        "\n",
        "Các biến `train_y`, `val_y`, `test_y` lúc này là một vector chứa các giá trị 0, 1,.., 9; nhưng để tính hàm lỗi của softmax regression, ta nên chuyển chúng về dạng ma trận one-hot (one-of-k). Giả sử ta có vector label có 6 phần tử, mỗi phần tử nằm trong khoảng từ 0 đến 4:\n",
        "\n",
        "\\begin{equation}\n",
        "\ty = [3,4,0,0,2,1]^T \\tag{17}\n",
        "\\end{equation}\n",
        "\n",
        "Ta sẽ có biến đổi one-hot tương ứng của nó là:\n",
        "\\begin{equation}\n",
        "y = \\begin{bmatrix}\n",
        "\t0 & 0 & 0 & \\color{red}1 & 0\\\\\n",
        "\t0 & 0 & 0 & 0 & \\color{red}1\\\\\n",
        "\t\\color{red}1 & 0 & 0 & 0 & 0\\\\\n",
        "\t\\color{red}1 & 0 & 0 & 0 & 0\\\\\n",
        "\t0 & 0 & \\color{red}1 & 0 & 0\\\\\n",
        "\t0 & \\color{red}1 & 0 & 0 & 0\n",
        "\\end{bmatrix} \\tag{18}\n",
        "\\end{equation}\n",
        "\n",
        "Label thứ nhất có giá trị là 3, vì vậy nên trong hàng thứ nhất ở ma trận trên cột 3 có giá trị 1, tất cả các cột khác trong hàng này là 0. Tương tự cho hàng thứ 2, label là 4, nên cột 4 trong hàng 2 có giá trị là 1.\n",
        "\n",
        "\n",
        "Để việc biến đổi giá trị của mảng sang dạng one-hot được nhanh chóng, ta nên sử dụng index array hay index vector trên ma trận đơn vị. Tham khảo thêm ở đây: [Numpy basic indexing - Index arrays](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.indexing.html#index-arrays)."
      ]
    },
    {
      "metadata": {
        "id": "fGlHfM_lkgVT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tính các giá trị phân loại\n",
        "\n",
        "Để tính các giá trị phân loại trong bài này, ta hiện thực các công thức sau trong hàm `feed_forward` và `softmax`:\n",
        "\n",
        "\\begin{equation}\n",
        "z = xw \\space, \\quad x \\in R^{m\\times D}, w \\in R^{D \\times K} \\tag{19}\n",
        "\\end{equation}\n",
        "\n",
        "Trong đó, $m$ là số lượng mẫu dữ liệu, $D$ là số lượng đặc trưng của dữ liệu đầu vào (785 sau khi thêm 1 vào cuối), $K$ là số lượng nhãn trong bài toán ta đang làm (10).\n",
        "\n",
        "\\begin{equation}\n",
        "z_{max} = [max(z^{(0)}), max(z^{(1)}),.., max(z^{(m-1)})]^T  \\tag{20}\n",
        "\\end{equation}\n",
        "\n",
        "Tại đây, $z_{max}$ là một vector cột (kích thước $m \\times 1$).\n",
        "\n",
        "\\begin{equation}\n",
        "z' = e^{z - z_{max}} \\tag{21}\n",
        "\\end{equation}\n",
        "\n",
        "Trong biểu thức trên, ta sẽ dùng cột thứ nhất của $z$ trừ cho $z_{max}$, cột thứ 2 của $z$ trừ cho $z_{max}$, v.v. Sau đó, ta tính lũy thừa cho từng phần tử trên hiệu đã tính. Kết quả tại bước này là một ma trận $z'$ có kích thước $m \\times K$.\n",
        "\n",
        "Kế tiếp, ta cần tính tổng sau:\n",
        "\n",
        "\\begin{equation}\n",
        "s = \\sum^{K-1}_{k=0}z'^{(i)}_{k} ,\\quad 0\\le i \\le m-1\\tag{22}\n",
        "\\end{equation}\n",
        "\n",
        "Như vậy, $s$ sẽ là vector chứa tổng từng hàng của ma trận $z'$. $s$ có kích thước $m \\times 1$. Sau cùng, ta có thể tính softmax bằng cách lấy mỗi phần tử trong $z'$ chia cho tổng hàng tương ứng:\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}^{(i)}_{k} = \\frac{z'^{(i)}_{k}}{s^{(i)}}, \\quad 0\\le i \\le m-1, 0\\le k \\le K-1 \\tag{23}\n",
        "\\end{equation}\n",
        "\n",
        "Sau khi tổng hợp lại toàn bộ các phần tử $i, k$ của $\\hat{y}$, ta sẽ có ma trận có kích thước $m \\times K$. Trong ma trận này, mỗi hàng thứ $i$ biểu diễn vector xác suất lớp của mẫu ảnh thứ $i$. Vì vậy, tổng của mỗi hàng luôn bằng 1."
      ]
    },
    {
      "metadata": {
        "id": "Yy_5nMf7mOTW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 13: feed_forward\n",
        "\n",
        "Các bạn hoàn thành hàm `feed_forward` ở phần class [SoftmaxClassifier](https://colab.research.google.com/drive/1_DcdsXqPkAM3UB4GCHZHf_JlJRRRCA9T#scrollTo=jKsh9eo5hOMq&line=77&uniqifier=1)"
      ]
    },
    {
      "metadata": {
        "id": "2Oz_NZPmmp4V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 14: softmax\n",
        "\n",
        "Các bạn hoàn thành hàm `softmax` ở phần class [SoftmaxClassifier](https://colab.research.google.com/drive/1_DcdsXqPkAM3UB4GCHZHf_JlJRRRCA9T#scrollTo=jKsh9eo5hOMq&line=77&uniqifier=1)"
      ]
    },
    {
      "metadata": {
        "id": "8wm4-xOlnVMZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tính độ lỗi\n",
        "Công thức tính độ lỗi category như sau:\n",
        "\n",
        "\\begin{equation}\n",
        "J(w) = -\\frac{1}{m}\\sum_{i=0}^{m-1}\\sum_{k=0}^{K-1} y^{(i)}_k \\log\\hat{y}^{(i)}_k \\tag{24}\n",
        "\\end{equation}\n",
        "\n",
        "Trong đó:\n",
        "- $y^{(i)}_k$ là phần tử hàng $i$ cột $k$ trong ma trận nhãn one-hot $y$ (đã đề cập trong phần trước).\n",
        "- $\\hat{y}^{(i)} \\in (0, 1)$ là hàng $i$ cột $k$ trong ma trận $\\hat{y}$."
      ]
    },
    {
      "metadata": {
        "id": "SSvZIuG-oUwn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 15: compute_loss\n",
        "Các bạn hoàn thành hàm `compute_loss` ở phần class [SoftmaxClassifier](https://colab.research.google.com/drive/1_DcdsXqPkAM3UB4GCHZHf_JlJRRRCA9T#scrollTo=jKsh9eo5hOMq&line=77&uniqifier=1)"
      ]
    },
    {
      "metadata": {
        "id": "x-NMfsp0o0Ja",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tính đạo hàm\n",
        "Công thức tính đạo hàm theo từng tham số $w_{jk}$ được biểu diễn như sau:\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial  J(w_{jk})}{\\partial w_{jk}} = \\frac{1}{m}\\sum_{i=0}^{m-1} x^{(i)}_j (\\hat{y}^{(i)}_k - y^{(i)}_k) \\tag{25}\n",
        "\\end{equation}\n",
        "\n",
        "Với $0 \\le j \\le D-1$. Viết lại dưới dạng ma trận ta có được:\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial  J(w)}{\\partial w} = \\frac{1}{m}x^T(\\hat{y} - y) \\tag{26}\n",
        "\\end{equation}"
      ]
    },
    {
      "metadata": {
        "id": "gHzTgKgeqLMM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 16: get_grad\n",
        "Các bạn hoàn thành hàm `get_grad` ở phần class [SoftmaxClassifier](https://colab.research.google.com/drive/1_DcdsXqPkAM3UB4GCHZHf_JlJRRRCA9T#scrollTo=jKsh9eo5hOMq&line=77&uniqifier=1)\n"
      ]
    },
    {
      "metadata": {
        "id": "bysiSaSEqiae",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Đề xuất điều kiện dùng vòng lặp huấn luyện\n",
        "\n",
        "Trong bài này, ngoài việc sử dụng `train_x`, `train_y` để huấn luyện, file mẫu còn cung cấp cho các bạn các biến `val_x`, `val_y` để thực hiện việc validation. Toàn bộ các giá trị lỗi validation được lưu trong biến `all_val_loss`. Trong phần này, nhiệm vụ của các bạn là đề xuất ra điều kiện dừng khác (ngoài việc `e` đạt `num_epoch`) trong quá trình huấn luyện. Dựa vào độ lỗi validation, bạn có thể sử dụng các tiêu chí mình tự đề ra để tránh việc quá trình huấn luyện bị overfitting"
      ]
    },
    {
      "metadata": {
        "id": "i1qjvU6MrE3G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 17: is_stop_training\n",
        "\n",
        "Các bạn hoàn thành hàm `is_stop_training` nhận vào mảng `all_val_loss` và trả về giá trị boolean True hoặc False quyết định có dừng việc huấn luyện không. Nếu loss trên tập validation tăng hơn n (patience) lần liên tiếp thì trả về True, ngược lại thì False"
      ]
    },
    {
      "metadata": {
        "id": "_Xc5fXhhkfUC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: is_stop_training\n",
        "def is_stop_training(all_val_loss, patience=5):\n",
        "    \"\"\"is_stop_training\n",
        "    Check whether training need to be stopped\n",
        "\n",
        "    :param all_val_loss: list of all validation loss values during training\n",
        "    \"\"\"\n",
        "    is_stopped = False\n",
        "    ### START CODE HERE ###\n",
        "    counter = 0;\n",
        "    \n",
        "    for i in range(1,len(all_val_loss)):\n",
        "        if all_val_loss[i] > all_val_loss[i-1]:\n",
        "            counter += 1 \n",
        "        else:\n",
        "            counter = 0                \n",
        "    if counter >= patience :    \n",
        "        is_stopped = True\n",
        "    else:\n",
        "        is_stopped = False\n",
        "    ### END CODE HERE ###\n",
        "    return is_stopped\n",
        "\n",
        "### SANITY CHECK\n",
        "assert is_stop_training([1,2,3,4,5,6]) == True, \"Wrong\"\n",
        "assert is_stop_training([1,2,3])==False, \"Wrong\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SaMfOmffvslM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Đánh giá mô hình trên dữ liệu test\n",
        "\n",
        "Để đánh giá mô hình phân loại nhiều lớp, ta cần sử dụng một khái niệm gọi là confusion matrix. Giả sử ta có bài toán phân loại 3 lớp, thì confusion matrix có dạng sau:\n",
        "\n",
        "<table>\n",
        "    <th>\n",
        "        <td>Lớp 1</td>\n",
        "        <td>Lớp 1</td>\n",
        "        <td>Lớp 1</td>\n",
        "    </th>\n",
        "    <tr>\n",
        "        <td>Lớp 1</td>\n",
        "        <td>$N_{11}$</td>\n",
        "        <td>$N_{12}$</td>\n",
        "        <td>$N_{13}$</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Lớp 2</td>\n",
        "        <td>$N_{21}$</td>\n",
        "        <td>$N_{22}$</td>\n",
        "        <td>$N_{23}$</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Lớp 3</td>\n",
        "        <td>$N_{31}$</td>\n",
        "        <td>$N_{32}$</td>\n",
        "        <td>$N_{33}$</td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "Trong đó, $N_{kl}$ là tổng số mẫu thực chất thuộc lớp $k$ và bộ phân loại phân loại thành lớp $l$. Bộ phân loại càng tốt thì các ô trên đường chéo chính sẽ càng cao hơn so với các ô xung quanh. Khi tiến hành kiểm thử, người ra đề đã tính được confusion matrix như sau:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>0.93</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0.02</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0.05</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>0</td>\n",
        "        <td>0.95</td>\n",
        "        <td>0</td>\n",
        "        <td>0.05</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>0.02</td>\n",
        "        <td>0.02</td>\n",
        "        <td>0.59</td>\n",
        "        <td>0.02</td>\n",
        "        <td>0.22</td>\n",
        "        <td>0</td>\n",
        "        <td>0.13</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>0.05</td>\n",
        "        <td>0.03</td>\n",
        "        <td>0.03</td>\n",
        "        <td>0.82</td>\n",
        "        <td>0.05</td>\n",
        "        <td>0</td>\n",
        "        <td>0.03</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0.07</td>\n",
        "        <td>0.05</td>\n",
        "        <td>0.77</td>\n",
        "        <td>0</td>\n",
        "        <td>0.12</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0.89</td>\n",
        "        <td>0</td>\n",
        "        <td>0.09</td>\n",
        "        <td>0.02</td>\n",
        "        <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>0.21</td>\n",
        "        <td>0</td>\n",
        "        <td>0.08</td>\n",
        "        <td>0.02</td>\n",
        "        <td>0.17</td>\n",
        "        <td>0</td>\n",
        "        <td>0.51</td>\n",
        "        <td>0</td>\n",
        "        <td>0.02</td>\n",
        "        <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0.04</td>\n",
        "        <td>0</td>\n",
        "        <td>0.86</td>\n",
        "        <td>0</td>\n",
        "        <td>0.1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0.02</td>\n",
        "        <td>0</td>\n",
        "        <td>0.04</td>\n",
        "        <td>0</td>\n",
        "        <td>0.02</td>\n",
        "        <td>0.93</td>\n",
        "        <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0.02</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0</td>\n",
        "        <td>0.98</td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "Bạn cần đạt được kết quả tương tự hoặc tốt hơn sau khi hoàn tất bài tập 2 này."
      ]
    },
    {
      "metadata": {
        "id": "jcf1mHx80syW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 18: softmax_test"
      ]
    },
    {
      "metadata": {
        "id": "w7todI-yvOCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: softmax_test\n",
        "def softmax_test(y_hat, test_y):\n",
        "    \"\"\"test\n",
        "    Compute the confusion matrix based on labels and predicted values \n",
        "\n",
        "    :param classifier: the trained classifier\n",
        "    :param y_hat: predicted probabilites, output of classifier.feed_forward\n",
        "    :param test_y: test labels\n",
        "    \"\"\"\n",
        "\n",
        "    y_hat = np.argmax(y_hat, axis=1)\n",
        "    test_y = np.argmax(test_y, axis=1)\n",
        "    confusion_mat = np.zeros((10,10))\n",
        "    ### START CODE HERE ###\n",
        "    for i in range(len(y_hat)):\n",
        "        confusion_mat[test_y[i],y_hat[i]] += 1\n",
        "    confusion_mat = confusion_mat/np.sum(confusion_mat,axis=1)\n",
        "    ### END CODE HERE ###\n",
        "    return confusion_mat\n",
        "\n",
        "### SANITY CHECK\n",
        "y_hat = np.eye(20, 10)\n",
        "test_y = y_hat > 0.5\n",
        "assert np.trace(softmax_test(y_hat, test_y)) == 10, \"Wrong\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VpXPqYoQzOod",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Vòng lặp huấn luyện"
      ]
    },
    {
      "metadata": {
        "id": "Kk6MG4qp0LYg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_softmax_loss(train_loss, val_loss):\n",
        "    plt.figure(1)\n",
        "    plt.clf()\n",
        "    plt.plot(train_loss, color='b')\n",
        "    plt.plot(val_loss, color='g')\n",
        "\n",
        "\n",
        "def draw_weight(w):\n",
        "    label_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "    plt.figure(2, figsize=(8, 6))\n",
        "    plt.clf()\n",
        "    w = w[0:(28*28),:].reshape(28, 28, 10)\n",
        "    for i in range(10):\n",
        "        ax = plt.subplot(3, 4, i+1)\n",
        "        plt.imshow(w[:,:,i], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        ax.set_title(label_names[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bvi8LlauvQvr",
        "colab_type": "code",
        "outputId": "94aae2b8-685f-44b6-f843-470eab5948e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Training { display-mode: \"both\" }\n",
        "num_epoch = 10000 #@param {type:\"integer\"}\n",
        "learning_rate = 0.01 #@param {type:\"number\"}\n",
        "momentum_rate = 0.9 #@param {type:\"number\"}\n",
        "epochs_to_draw = 10 #@param {type:\"integer\"}\n",
        "update_weight_method = \"normal\" #@param [\"normal\", \"momentum\"]\n",
        "\n",
        "np.random.seed(2018)\n",
        "\n",
        "# Load data from file\n",
        "# Make sure that fashion-mnist/*.gz files is in data/\n",
        "train_x, train_y, val_x, val_y, test_x, test_y = get_mnist_data()\n",
        "num_train = train_x.shape[0]\n",
        "num_val = val_x.shape[0]\n",
        "num_test = test_x.shape[0]  \n",
        "\n",
        "# Convert label lists to one-hot (one-of-k) encoding\n",
        "train_y = create_one_hot(train_y)\n",
        "val_y = create_one_hot(val_y)\n",
        "test_y = create_one_hot(test_y)\n",
        "\n",
        "# Normalize our data\n",
        "train_x, val_x, test_x = normalize(train_x, val_x, test_x)\n",
        "\n",
        "# Pad 1 as the last feature of train_x and test_x\n",
        "train_x = add_one(train_x) \n",
        "val_x = add_one(val_x)\n",
        "test_x = add_one(test_x)\n",
        "\n",
        "# Create classifier\n",
        "num_feature = train_x.shape[1]\n",
        "dec_classifier = SoftmaxClassifier((num_feature, 10))\n",
        "momentum = np.zeros_like(dec_classifier.w)\n",
        "\n",
        "# Define hyper-parameters and train-related parameters\n",
        "all_train_loss = []\n",
        "all_val_loss = []\n",
        "plt.ion()\n",
        "\n",
        "for e in range(num_epoch):    \n",
        "    train_y_hat = dec_classifier.feed_forward(train_x)\n",
        "    val_y_hat = dec_classifier.feed_forward(val_x)\n",
        "\n",
        "    train_loss = dec_classifier.compute_loss(train_y, train_y_hat)\n",
        "    val_loss = dec_classifier.compute_loss(val_y, val_y_hat)\n",
        "\n",
        "    grad = dec_classifier.get_grad(train_x, train_y, train_y_hat)\n",
        "\n",
        "    # dec_classifier.numerical_check(train_x, train_y, grad)\n",
        "    # Updating weight: choose either normal SGD or SGD with momentum\n",
        "    if update_weight_method == \"normal\":\n",
        "        dec_classifier.update_weight(grad, learning_rate)\n",
        "    else:\n",
        "        dec_classifier.update_weight_momentum(grad, learning_rate, momentum, momentum_rate)\n",
        "\n",
        "    all_train_loss.append(train_loss) \n",
        "    all_val_loss.append(val_loss)\n",
        "    \n",
        "    if is_stop_training(all_val_loss):\n",
        "        break\n",
        "\n",
        "    if (e % epochs_to_draw == epochs_to_draw-1):\n",
        "        from IPython.display import clear_output\n",
        "        clear_output(wait=True)\n",
        "        plot_softmax_loss(all_train_loss, all_val_loss)\n",
        "        draw_weight(dec_classifier.w)\n",
        "        plt.show()\n",
        "        plt.pause(0.1) \n",
        "        print(\"Epoch %d: train loss: %.5f || val loss: %.5f\" % (e+1, train_loss, val_loss))\n",
        "\n",
        "y_hat = dec_classifier.feed_forward(test_x)\n",
        "np.set_printoptions(precision=2)\n",
        "confusion_mat = softmax_test(y_hat, test_y)\n",
        "print('Confusion matrix:')\n",
        "print(confusion_mat)\n",
        "print('Diagonal values:')\n",
        "print(confusion_mat.flatten()[0::11])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading fashion MNIST data...\n",
            "Confusion matrix:\n",
            "[[0.44 0.05 0.02 0.1  0.21 0.   0.26 0.   0.   0.  ]\n",
            " [0.02 0.83 0.02 0.17 0.02 0.   0.   0.   0.   0.  ]\n",
            " [0.25 0.02 0.26 0.03 0.23 0.02 0.02 0.   0.11 0.  ]\n",
            " [0.   0.33 0.   0.42 0.07 0.   0.   0.   0.02 0.  ]\n",
            " [0.11 0.07 0.11 0.03 0.3  0.02 0.09 0.   0.15 0.  ]\n",
            " [0.05 0.05 0.02 0.05 0.   0.47 0.02 0.08 0.13 0.14]\n",
            " [0.22 0.09 0.17 0.   0.23 0.   0.28 0.02 0.04 0.  ]\n",
            " [0.   0.07 0.   0.   0.   0.53 0.   0.08 0.07 0.18]\n",
            " [0.   0.   0.04 0.1  0.07 0.   0.11 0.04 0.63 0.06]\n",
            " [0.   0.   0.   0.   0.   0.04 0.02 0.   0.   0.94]]\n",
            "Diagonal values:\n",
            "[0.44 0.83 0.26 0.42 0.3  0.47 0.28 0.08 0.63 0.94]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o-5Ot3UI05wM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Thực hiện bài 2 với Tensorflow**"
      ]
    },
    {
      "metadata": {
        "id": "iGmLYGhr1AET",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Định nghĩa mô hình Softmax Regression bằng Tensorflow eager execution\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "BINeWJlQAxiF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tại đây, các bạn cần định nghĩa mô hình SoftmaxRegressionTF. Để định nghĩa mô hình này, các bạn nên tham khảo ví dụ ở mô hình LogisticRegressionTF ở trên."
      ]
    },
    {
      "metadata": {
        "id": "0RU3mpbEyPZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SoftmaxRegressionTF(tf.keras.Model):\n",
        "    def __init__(self, num_class):\n",
        "        super(SoftmaxRegressionTF, self).__init__()\n",
        "        # TODO 19: init all weights \n",
        "        ### START CODE HERE ###\n",
        "        self.dense = tf.keras.layers.Dense(num_class)\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        # TODO 20: implement your feedforward         \n",
        "        ### START CODE HERE ###\n",
        "        output = self.dense(inputs)\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        # softmax op does not exist on the gpu\n",
        "        with tf.device('/cpu:0'):\n",
        "            output = tf.nn.softmax(output)        \n",
        "        return output\n",
        "\n",
        "### SANITY CHECK    \n",
        "logistic_regressor = SoftmaxRegressionTF(10)\n",
        "dummy_x = tf.zeros((1, 13))\n",
        "assert logistic_regressor(dummy_x).numpy().sum() == 1, \"Wrong\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fx6PKo9OBN-v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 19: cài đặt hàm __init__ \n",
        "Các bạn cần khởi tạo tất cả các trọng số ở hàm init của lớp SoftmaxRegressionTF."
      ]
    },
    {
      "metadata": {
        "id": "j4GbtrTdBV7Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TODO 20: cài đặt hàm call\n",
        "Cài đặt feedforward trong hàm call ở lớp SoftmaxRegressionTF."
      ]
    },
    {
      "metadata": {
        "id": "N7dHYqGc6aax",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Huấn luyện với tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "mEqbmm1M6Zu8",
        "colab_type": "code",
        "outputId": "aa013017-76d4-48d3-eaa8-f183c014a322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Training { display-mode: \"both\" }\n",
        "num_epoch = 10 #@param {type:\"integer\"}\n",
        "learning_rate = 0.001 #@param {type:\"number\"}\n",
        "num_classes = 10\n",
        "\n",
        "tf.set_random_seed(2018)\n",
        "\n",
        "# Load data from file\n",
        "# Make sure that fashion-mnist/*.gz files is in data/\n",
        "train_x, train_y, val_x, val_y, test_x, test_y = get_mnist_data()\n",
        "num_train = train_x.shape[0]\n",
        "num_val = val_x.shape[0]\n",
        "num_test = test_x.shape[0]  \n",
        "\n",
        "\n",
        "# Convert label lists to one-hot (one-of-k) encoding\n",
        "train_y = create_one_hot(train_y)\n",
        "val_y = create_one_hot(val_y)\n",
        "test_y = create_one_hot(test_y)\n",
        "\n",
        "# Normalize our data\n",
        "train_x, val_x, test_x = normalize(train_x, val_x, test_x)\n",
        "\n",
        "device = '/cpu:0' if tfe.num_gpus() == 0 else '/gpu:0'\n",
        "\n",
        "with tf.device(device):\n",
        "    # build model and optimizer\n",
        "    model = SoftmaxRegressionTF(num_classes)\n",
        "    model.compile(optimizer=tf.train.AdamOptimizer(learning_rate), loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "\n",
        "    # train\n",
        "    model.fit(train_x, train_y, batch_size=batch_size, epochs=num_epoch,\n",
        "              validation_data=(val_x, val_y), verbose=2)\n",
        "\n",
        "    # evaluate on test set\n",
        "    scores = model.evaluate(test_x, test_y, 32, verbose=2)\n",
        "    \n",
        "    y_hat = model.predict(test_x)\n",
        "\n",
        "\n",
        "    confusion_mat = softmax_test(y_hat, test_y)\n",
        "    print('Confusion matrix:')\n",
        "    print(confusion_mat)\n",
        "    print('Diagonal values:')\n",
        "    print(confusion_mat.flatten()[0::11])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading fashion MNIST data...\n",
            "Train on 2500 samples, validate on 500 samples\n",
            "Epoch 1/10\n",
            " - 0s - loss: 0.1785 - acc: 0.9326 - val_loss: 0.1228 - val_acc: 0.9502\n",
            "Epoch 2/10\n",
            " - 0s - loss: 0.1076 - acc: 0.9583 - val_loss: 0.1108 - val_acc: 0.9530\n",
            "Epoch 3/10\n",
            " - 0s - loss: 0.0959 - acc: 0.9622 - val_loss: 0.1045 - val_acc: 0.9542\n",
            "Epoch 4/10\n",
            " - 0s - loss: 0.0871 - acc: 0.9662 - val_loss: 0.1022 - val_acc: 0.9596\n",
            "Epoch 5/10\n",
            " - 0s - loss: 0.0826 - acc: 0.9682 - val_loss: 0.1027 - val_acc: 0.9590\n",
            "Epoch 6/10\n",
            " - 0s - loss: 0.0765 - acc: 0.9709 - val_loss: 0.1016 - val_acc: 0.9586\n",
            "Epoch 7/10\n",
            " - 0s - loss: 0.0726 - acc: 0.9721 - val_loss: 0.1016 - val_acc: 0.9600\n",
            "Epoch 8/10\n",
            " - 0s - loss: 0.0689 - acc: 0.9739 - val_loss: 0.0999 - val_acc: 0.9602\n",
            "Epoch 9/10\n",
            " - 0s - loss: 0.0677 - acc: 0.9744 - val_loss: 0.0985 - val_acc: 0.9586\n",
            "Epoch 10/10\n",
            " - 0s - loss: 0.0646 - acc: 0.9750 - val_loss: 0.1038 - val_acc: 0.9606\n",
            " - 0s - loss: 0.0955 - acc: 0.9632\n",
            "Confusion matrix:\n",
            "[[0.93 0.03 0.02 0.   0.   0.   0.02 0.   0.   0.  ]\n",
            " [0.   0.97 0.   0.05 0.   0.   0.   0.   0.   0.  ]\n",
            " [0.04 0.02 0.35 0.03 0.28 0.   0.26 0.   0.   0.  ]\n",
            " [0.02 0.02 0.   0.88 0.02 0.   0.04 0.   0.   0.  ]\n",
            " [0.   0.   0.04 0.05 0.81 0.   0.08 0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.92 0.   0.06 0.   0.02]\n",
            " [0.27 0.   0.02 0.03 0.21 0.   0.51 0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.08 0.   0.78 0.   0.14]\n",
            " [0.   0.   0.   0.03 0.   0.04 0.02 0.   0.91 0.02]\n",
            " [0.   0.   0.   0.   0.   0.02 0.   0.   0.   0.98]]\n",
            "Diagonal values:\n",
            "[0.93 0.97 0.35 0.88 0.81 0.92 0.51 0.78 0.91 0.98]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}